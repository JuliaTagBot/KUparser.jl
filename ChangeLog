2015-03-22  Deniz Yuret  <dyuret@ku.edu.tr>

	* DEPRELS: Unfortunately they change a lot.
	acl11: NMOD, VMOD, P, PMOD, SUB, ROOT, OBJ, AMOD, VC, SBAR, PRD, DEP (from: acl11/src/english/dependency/label/penn.h)
	conll07: NMOD, P, PMOD, SBJ, ADV, OBJ, COORD, VMOD, ROOT, AMOD, VC, IOBJ, CC, PRT, PRN, LGS, DEP, GAP, EXP, TMP
	conllWSJToken_wikipedia2MUNK-100: NMOD, P, PMOD, SBJ, OBJ, ROOT, ADV, VC, COORD, NAME, DEP, TMP, CONJ, LOC, AMOD, APPO, PRD, IM, SUB, OPRD, SUFFIX, TITLE, DIR, MNR, POSTHON, PRP, PRT, LGS, EXT, PRN, LOC-PRD, EXTR, DTV, PUT, GAP-SBJ, GAP-OBJ, DEP-GAP, GAP-TMP, GAP-PRD, PRD-TMP, PRD-PRP, BNF, GAP-LGS, GAP-LOC, DIR-GAP, LOC-OPRD, VOC, GAP-PMOD, ADV-GAP, GAP-VC, EXT-GAP, GAP-NMOD, AMOD-GAP, DTV-GAP, GAP-LOC-PRD, GAP-MNR, DIR-PRD, GAP-PRP, EXTR-GAP, MNR-PRD, LOC-TMP, GAP-OPRD, LOC-MNR, GAP-SUB, GAP-PUT, MNR-TMP, DIR-OPRD

	So we have conll2dict.jl which takes a conll corpus and construct
	dictionaries for forms, postags, and deprels.  Then we have
	conll2jld.jl which takes this dictionary and saves the conll
	corpus in a jld file replacing strings with ints (based on their
	position in dict).  Note: deprel ROOT is special, it does not
	create a new left/right move and is represented by the special
	value 0.

	* Summary:

	+ conll07 experiments: comparing best test result (should be test
	at best validation and should take averages) to GN13 archybrid
	result (we are not using deprels).

	parser	score	GN13
	oparser	.8699	.8643	03210931-opconll07.out
	gparser	.8793	.8762	03210908-gpconll07.out
	beam10	.8865	---	03221208-bpconll07.out

	+ acl11 experiments: ZN11 for comparison has word accuracy
	dev=.9314 test=.9290.  Word accuracy (excluding punct) is about 1%
	higher than head accuracy (including punct).  We are not using
	deprels.  We are using nbeam=10, they use 64.  We are using
	archybrid, they use arceager.  test1 is the test score at best dev
	result.  test2 is the best test score.

	parser	dev	test1	test2
	oparser	.9093	.9046	.9060	03212217-opacl11.out
	gparser	.9136	.9096	.9109	03212217-gpacl11.out
	beam10	.9158	.9122	.9145	bpacl11.out -- running at epoch=132

	+ conllWSJToken_wikipedia2MUNK-100 experiments: Different gold
	head than acl11.  Latestop better than earlystop.
	- How about train on all mincost state/move pairs (if multiple).
	- beam64 too slow, get pepochs to work.

	parser	dev	test1	test2
	beam10a	.9186	.9132	.9136	03201925-julia3_btrain_jl.out: using whole beam to train, quit at epoch=77
	beam64	.9195	.9129	.9136	bparse64.out -- running at epoch=49
	beam10l	.9211	.9169	.9171	03220927-bparselatestop.out: no earlystop, crashed at epoch=207
	beam10	.9205	.9150	.9166	03220548-bparsedbg.out: earlystop

	+ gfeatures experiments: Large feature sets more effective with
	nnets compared to perceptron.  Redo feature optimization and/or
	take a careful look at ZN11 and GN13 feature sets.

2015-03-21  Deniz Yuret  <dyuret@ku.edu.tr>

	* Summary:
	+ Everybody is using deprels even when training for unlabelled
	accuracy.
	+ ZN11 uses different heads than Husnu&Volkan's dataset.  I have
	created acl11 files to match ZN11.
	+ Nnets seem to handle extra features better than perceptrons,
	high dimensional feature sets seem to do well.
	+ We are better than GN13 even without deprels, however this is
	directly optimizing on test data, we need to use dev.
	+ We have the code for ZN11 and GN13, we can take a look at the
	feature sets in detail.
	+ Suzuki uses 3.5B words for semisupervised learning, we should
	grow our LM and SCODE corpora as well.
	+ ZN11 uses arceager, GN13 best result with arceasy.

	* ZN11: (Zhang&Nivre11) nbeam=64 dev=.9314 tst=.9290
	wordacc (excluding punct) conv=Penn2Malt.  parser=arceager.
	learner=perceptron.  uses labels to improve link accuracy!  (seems
	they get .65) also check out their feature set, and their distance
	encoding.  Their whole dataset is projective!

	* GN13: (Goldberg&Nivre13) .8643/.8762 static/dynamic archybrid on
	conll07 headacc (including punct).  no beam.  I think uses labels,
	but better check feature specs.

	* TODO: parser and training
	- ** add deprel labels as features! **: features.jl, archybrid.jl
	-- output two variables (move+label) or one (movelabel)?
	- check features and encodings of zhang&nivre11.
	- use oparser for fselect.  faster if only test at the end.
	- need fselect again for labeled parser.
	- try previous moves as features? (rnn idea)
	- try arceasy (better on Goldberg&Nivre13) arceager (Zhang&Nivre11).
	- train.jl: write pepochs option to get nbeam=64 to work.
	- train.jl: implement earlystop for efficiency (Zhang does it)
	- train.jl: longer training (stop if 2x best epoch)
	- train.jl: save models
	- train.jl: compute eval.py (wordacc) score.
	= can we use rnn's to learn parser-action sequences? prepare
	  ordered data for ozan.
	= better vectors: fastsubs and scode on bigger better data.  which
	  data did volkan use? onur interested. sent email.
	+ are they (Goldberg,Zhang) using the deprels during parsing?
	  (BILOU is better than BIO) YES!
	+ which arc system are they (Zhang&Nivre11) using? arceager.

	* TODO: model and optimization
	- play with optimization, rmsprop, adam, layers, dropout, hidden layers?
	- alternative to adagrad?
	- try more hidden layers.

	* TODO: features
	= fv1768: memory error
	x try bparse 10 epochs all Flist: oparse instead for fselect.
	- try local search around best feats
	- feature select with acl11
	- feature select with conll07
	- features from ZN11 and GN13

2015-03-20  Deniz Yuret  <dyuret@ku.edu.tr>

	* ~/src/acl11: Got Yue Zhang's acl11 data.  Heads are different!
	+ ** generate new dataset with acl11 heads. **
	+ generate new dataset with conll07.

	Note: fv021a may not be ideal for acl11! run gfeatures after fixing bugs.
	Note: using fv022b for conll07.

	* 03210931-opconll07.out:
	$$480064 0.50531 opconll07  dyuret       r     03/20/2015 18:39:10 ilac.q@ilac-0-0.local
	1	0.8383803	0.8205077
	2	0.8559474	0.841695
	4	0.87357944	0.8420947
	8	0.8902576	0.84929043
	16	0.91164714	0.8560864
	32	0.9369286	0.85808516
	64	0.9609493	0.86128324
	128	0.97914565	0.86128324
	170	0.98390406	0.86987805	*** (compare to GN13=.8643)
	256	0.9885506	0.86508095

	* 03210908-gpconll07.out:
	$$480065 0.50531 gpconll07  dyuret       r     03/20/2015 18:45:10 ilac.q@ilac-3-0.local
	1	0.8376861	0.8237058
	2	0.79815173	0.77953225
	4	0.87328166	0.85108936
	8	0.89544153	0.8604837
	16	0.91665864	0.86667997
	32	0.9414877	0.8712772
	64	0.964232	0.8702778
	128	0.9813267	0.8786728
	133	0.98199844	0.87927246	*** (compare to GN13=.8762)
	256	0.98990756	0.8724765

	* 03221208-bpconll07.out:
	@@480066 0.50531 bpconll07  dyuret       r     03/20/2015 18:45:55 ilac.q@ilac-2-1.local
	$ grep DATA bpconll07.out | awk '$2>=a{print;a=$2*2}'
	1	0.8489049	0.836698
	2	0.86899793	0.8554867
	4	0.8904457	0.8686788
	8	0.9080262	0.875075
	16	0.92726606	0.88227063
	32	0.94914156	0.88127124
	54	0.9653002	0.8864681	***
	64	0.9700833	0.8772736
	128	0.9850327	0.875075
	256	0.9918983	0.8680791

	* 03200918-gfeatures_sh.out: experiment with features (honnibal
	comment).  This is on husnu deps.
	+ try gparse 10 epochs all Flist
	$$479993 0.50531 _gfeatures dyuret       r     03/19/2015 10:46:40 ilac.q@ilac-2-3.local
	$$479998 0.50531 _gfeatures dyuret       r     03/19/2015 11:46:40 ilac.q@ilac-1-3.local
	= try to debug and fix the crashes
	$$480067 0.50531 gfeatures2 dyuret       qw    03/20/2015 19:19:08
	$$480068 0.50531 gfeatures3 dyuret       qw    03/20/2015 21:53:02
	@@480069 0.50531 gfeatures3 dyuret       r     03/22/2015 13:12:40 ilac.q@ilac-2-2.local
	$ egrep '^(DATA:.10|julia3)' _gfeatures_sh.out
	fv1768	0.92688215	0.9029838	0.8982076	(3348 dims, 865MiB)
	fv031a	0.9175582	0.90168756	0.8972373	(2512 dims)
	fv034	0.92510116	0.9013386	0.8971491	(2452 dims, 660MiB)
	fv021a	0.9179561	0.90113914	0.89709616	(1326 dims)
	fv022a	0.918115	0.9009896	0.8971138	(1426 dims)
	fv023	0.9185719	0.9005908	0.8966375	(1526 dims)
	fv022	0.9171161	0.9003415	0.8965669	(1516 dims)
	fv023a	0.91787714	0.8998679	0.89737844	(1616 dims)
	fv018	0.91692454	0.8995937	0.8934091	(1608 dims)
	fv804	0.91603404	0.89899546	0.89492625	(1604 dims)
	fv021	0.91659826	0.89894557	0.8955437	(1416 dims)
	fv708	0.9135615	0.89847195	0.89399123	(1408 dims)
	fv019	0.915633	0.8984221	0.89533204	(1411 dims)
	fv015a	0.914752	0.8978488	0.8922976	(1401 dims)
	fv018a	0.9154783	0.89777404	0.89423823	(1407 dims)
	fv017	0.9170309	0.8975247	0.89513797	(1508 dims)
	fv039	0.9245001	0.897450	0.89577305	(2744 dims, 727MiB)
	fv130	0.91527617	0.8966772	0.89319736	(3538 dims, 909MiB)
	fv808	0.91797924	0.89655256	0.89259756	(1608 dims)
	fv017a	0.916613	0.89615375	0.893021	(1508 dims)
	fv136	0.9144846	0.8956053	0.8926505	(3544 dims, 910MiB)
	fv012	0.9068354	0.88982224	0.88806367	(1200 dims)
	fv008	0.9009608	0.8860832	0.88349444	(800 dims)
	fv008w	0.8957652	0.8806242	0.8796309	(800 dims)
	fv022b died (1424 dims)
	fv084 died
	fv102 died (4638 dims, crashed again)


2015-03-19  Deniz Yuret  <dyuret@ku.edu.tr>

	* 03201925-julia3_btrain_jl.out: Train using beam parser. ~1h per
	epoch.  Training on the whole beam with nbeam=10.
	+ merge mincostpath with master after this one finishes.
	$$479844 0.50531 julia3_btr dyuret       r     03/17/2015 12:01:55 ilac.q@ilac-0-3.local
	1	0.8714639358032035	0.8880773736819803	0.8838649354315151
	2	0.8950433643212408	0.8938604581598824	0.890762825488674
	4	0.9122091687400475	0.903033626642072	0.8975901488956319
	8	0.9273346259121167	0.9078694817658349	0.9040117140639334
	16	0.9424559294340376	0.912007378418127	0.9076811798743913
	32	0.9569711670068192	0.9151481915397462	0.9107331874955896
	64	0.9691327587380277	0.9175910461898945	0.9127443370263214
	74	0.9711445121199407	0.9180397337786973	0.9135734951661845	*t*
	77	0.9718000903088589	0.9186130568088342	0.9132030202526286	*d*

	* bparse64.out: experiment with larger beams 1h22m/epoch
	@@479988 0.50531 bparse64   dyuret       r     03/19/2015 09:48:25 ilac.q@ilac-1-0.local
	1	0.88225925	0.8752399	0.87107474
	2	0.8944715	0.8857093	0.8815892
	4	0.9085364	0.8967271	0.8914861
	8	0.9206171	0.90582544	0.9008715
	16	0.93292725	0.9116833	0.9058465
	32	0.9474447	0.9167186	0.91170347
DATA:	45	0.9546024	0.9194855	0.9129384	*d*
DATA:	49	0.956676	0.918987	0.9136441	*t*

	* 03220927-bparselatestop.out: why is this different from static
	oracle training?  we are rewarding mincost state/move pairs on the
	beam.  are the mincost states on the beam that different than the
	mincost states for the static oracle?  why not use earlystop in
	gparser?  **why not follow the whole mincostpath and not use
	earlystop in bparser?**

	$$480009 0.50531 bparselate dyuret       r     03/19/2015 14:17:25 ilac.q@ilac-2-2.local
	$$480024 0.50531 bparselate dyuret       r     03/19/2015 17:07:40 ilac.q@ilac-2-2.local
	1	0.8824845	0.8760874	0.8711453
	2	0.8931568	0.8864322	0.8810599
	4	0.9077248	0.8963033	0.89115095
	8	0.92096025	0.9067976	0.8996013
	16	0.9335746	0.9120572	0.90686965
	32	0.94735837	0.9163447	0.91173875
	64	0.9624811	0.9194606	0.9139969
	121	0.9752039	0.9198843	0.9171371	*t*
	128	0.9760491	0.92015857	0.91664314
	129	0.97622174	0.9211307	0.9169078	*d*
	207	0.9833121	0.9198843	0.91528475	crashed

	* 03220548-bparsedbg.out: mincostpath bparser results: at most one
	xy pair per beam (the first one which has the initial mincost) is
	added to the training set. nbeam=10.  (18m50s per epoch) Note: trn
	improvement is slower compared to whole beam training.  dev/tst
	catches up and passes after 32 epochs.  Less overfitting?  Speed
	3x faster.

	$$479933 0.50531 bparsedbg  dyuret       r     03/18/2015 21:32:10 ilac.q@ilac-0-1.local
	1	0.8811414	0.8743675	0.87079245
	2	0.8940389	0.8873545	0.8804777
	4	0.9079269	0.89695144	0.8927387
	8	0.92069286	0.9061495	0.89916027
	16	0.9332304	0.9117581	0.9058112
	32	0.94746995	0.91639453	0.91230327
	64	0.9625506	0.9181644	0.9151789
	128	0.97627544	0.91808957	0.91576105
	130	0.97652704	0.9197597	0.9165726	*t*
	193	0.982411	0.92053246	0.91503775	*d*
	256	0.985992	0.9191365	0.91507304

	* bpacl11.out: Trying acl11 dependencies.
	@@480062 0.50531 bpacl11    dyuret       r     03/20/2015 18:27:55 ilac.q@ilac-2-3.local
	1	0.87517524	0.86920756	0.86677015
	2	0.88630337	0.8795274	0.87807846
	4	0.9019197	0.891617	0.8888046
	8	0.9159751	0.8992198	0.8985252
	16	0.92985153	0.9061495	0.9052113
	32	0.94513106	0.91220677	0.9099746
	64	0.9617148	0.9144004	0.9116329
	79	0.9671715	0.9158212	0.9121622	*d* (ZN11:9314w)
	121	0.9770028	0.91380215	0.9145438	*t* (ZN11:9290w)
	128	0.97827536	0.91502357	0.91406745
	132	0.9789954	0.9143754	0.91440266

	* TODO:
	+ headpct-wordpct diff around 1% according to vectorparser/ChangeLog.
	= compare Penn2Malt conversion with Zhang: emailed Zhang.
	+ check Suzuki11.
	+ merge mincostpath and structure code to experiment with other variants.
	= parse conll07 for static/dynamic comparison.
	= experiment with subsets of the beam to use for training (zhang email)?

	* Chen&Zhang&Zhang14: .9422 is best from related work Suzuki11 in
	http://www.aclweb.org/anthology/C14-1078. Conversion with
	Penn2Malt.  Uses Carreras07 decoder with MIRA and Bohnet2010 features.

	* Suzuki11: (condensed feature representations, semisupervised)
	cites dev/tst Suzuki11:9433/9422, Koo08:9330/9316, Chen09:?/9316,
	Suzuki09:9413/9379.  Uses 3.7b token for unsupervised learning (as
	Suzuki09).  Suzuki 09 uses conv=yamada parser=2nd-order.

	* Koo08: tst23=.9316 (excluding punct).  Uses Carreras07 (second
	order).  Cluster info adds +1.14.


2015-03-18  Deniz Yuret  <dyuret@ku.edu.tr>

	* todo:
	= write bparser:mincostpath - testing on *julia*
	= add options to gtrain/btrain - testing on {ogb}parsedbg.out
	+ try onur's problem
	x try bparser without dropout: no reason to do it with mincostpath, input similar to oparser.
	= try gparser with other fvectors

2015-03-16  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	+ solve memory problems: x=10GB, bparse=100GB!
	+ save networks: implement savenet, testnet or copy:save copy:test
	= beam earlystop? only train with mincostpath?  same with greedy?
	= play with features

	* memory:
	x do we need to wait for @everywhere gc()?
	x whos() does not work from inside meminfo: turn into macro?: still does not show locals
	= check out getBytes from http://stackoverflow.com/questions/28402989/check-size-in-bytes-of-variable-using-julia
	x if restarting workers does not help, just write code without DArrays.
	x maybe forget about workers and write multithreaded.
	+ but DArrays are only used for corpora, not the returned x!?  help debug gc().

2015-03-15  Deniz Yuret  <dyuret@ku.edu.tr>

	* upper-bound: These are head accuracies with oracle parser (less than 100% because of nonplanar trees?)
	evalheads(p1,trn) => 0.9940970160879469
	evalheads(p2,dev) => 0.9950395094349029
	evalheads(p3,tst) => 0.9935960764942489

	* 03160543-julia3_otrain_jl.out: Train using static oracle. 4m07s
	per epoch. (5m50s with testing)

	epoch	trn			dev			tst
	1	0.8739110847259238	0.8660916818306453	0.8615129489803119
	2	0.8855433734584665	0.8766607672557769	0.8707218968315574
	4	0.8988882432938818	0.8874541964753098	0.8828064356784984
	8	0.9100005473522885	0.8930877184236109	0.8891574341965987
	16	0.9229485867784949	0.9015130742577959	0.8943264413238303
	32	0.9391302151094494	0.9064486377346263	0.9001481899654223
	64	0.9567865368178622	0.9097639404741132	0.903288405899372
	128	0.9730323737826675	0.9098636488271805	0.9051054971420507
	256	0.9837520578340849	0.9088665652965077	0.9075047632488886

	* 03200328-oparsedbg.out: Replicating otrain results with new train.jl (6m22s/epoch)
	$$479920 0.50500 oparsedbg  dyuret       r     03/18/2015 19:55:10 ilac.q@ilac-0-2.local
	1	0.8737332	0.86576766	0.8628537
	2	0.8857002	0.87501556	0.8715687
	4	0.89788723	0.88446295	0.8803366
	8	0.91024685	0.8940349	0.88966906
	16	0.9238307	0.901538	0.89517325
	32	0.93902916	0.9065733	0.8999365
	64	0.95688546	0.90904105	0.9024416
	128	0.97318393	0.91016275	0.9060052
	254	0.98392576	0.9116335	0.9063228	*d*
	255	0.9839089	0.91013783	0.90736365	*t*
	256	0.98388153	0.910786	0.90690494

	* 03212217-opacl11.out: Trying the ACL11 Zhang dependencies.
	$$480059 0.50531 opacl11    dyuret       r     03/20/2015 18:15:10 ilac.q@ilac-2-0.local
	1	0.86862916	0.8634993	0.86227155
	2	0.88202244	0.87424284	0.87324464
	4	0.8953294	0.8846873	0.8833357
	8	0.90825427	0.8924396	0.8921036
	16	0.92300224	0.89936936	0.8979077
	32	0.9404091	0.9041554	0.9030238
	64	0.95960015	0.90749556	0.9038882
	128	0.9779785	0.908044	0.90415287
	205	0.9867804	0.9072712	0.90602285	*t*
	210	0.9871225	0.9092903	0.9046115	*d*
	256	0.9896782	0.9065234	0.9043998

	* 03171146-julia3_gtrain_jl.out: Train using greedy parser. 6m30s per epoch.
	1	0.8740110817786423	0.8695565470997333	0.8623244654576248
	2	0.8796424947475232	0.8704539222773388	0.8683755557123704
	4	0.8938568126413117	0.8808235909963357	0.8785018700162304
	8	0.9140688484970969	0.8979734277239075	0.8951732411262437
	16	0.9277031834851184	0.9051773562330184	0.9003246065909252
	32	0.941745927488453	0.9094149612383777	0.9050349304918496
	64	0.9574433595641392	0.9112595657701223	0.9091101545409639
	93	0.9657357467358857	0.9154223895106812	0.9110330957589443
	127	0.9721671361265142	0.9149986290101453	0.9128678286641733

	* 03192351-gparsedbg.out: Replicating gtrain results (6m32s/epoch) with new train.jl
	$$479926 0.50531 gparsedbg  dyuret       r     03/18/2015 19:58:55 ilac.q@ilac-0-0.local
	1	0.87359005	0.86753744	0.8616188
	2	0.88026565	0.87152576	0.86717594
	4	0.89791775	0.8860832	0.88430595
	8	0.9142257	0.90056586	0.8936737
	16	0.92736214	0.90445447	0.8997248
	32	0.9417891	0.90948975	0.9047703
	64	0.95761913	0.91292965	0.9092689
	128	0.9720545	0.91372734	0.91122717
	194	0.9796385	0.9158212	0.9123562	*d*
	238	0.98255104	0.9152479	0.9139616	*t*
	256	0.98354787	0.9134033	0.91325593

	* 03212217-gpacl11.out: Trying the acl11 dependencies.
	$$480058 0.50531 gpacl11    dyuret       r     03/20/2015 18:14:25 ilac.q@ilac-1-3.local
	1	0.8675871	0.8654436	0.86175996
	2	0.85359275	0.8475958	0.8446828
	4	0.8899264	0.87940276	0.87911934
	8	0.91075844	0.89585465	0.8929857
	16	0.92462856	0.901887	0.89970714
	32	0.94124806	0.90712166	0.90517604
	64	0.9581886	0.9111848	0.90812224
	116	0.9726871	0.9120572	0.9109096	*t*
	128	0.9751281	0.9124561	0.90872204
	184	0.98290575	0.9135778	0.90960413	*d*
	256	0.98849404	0.9113094	0.9093748

2015-03-14  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/oparser.jl: Oracle parser: useful for generating static oracle training data.
	julia> @time o2=KUparser.oparse(dev,feats,20);
	elapsed time: 2.306022569 seconds (430 MB allocated, 44.86% gc time in 6 pauses with 3 full sweep)
	julia> mean(vcat(o1[1]...) .== vcat(map(x->x.head,dev)...))
	0.9950395094349029

	* src/gparser.jl:
	x do not need to allocate p, y, etc. for the whole corpus in batch version.

	* TODO:
	+ return xy from gparser and bparser.
	+ train. (need logploss, need earlystop?, try rmsprop?, adam?: adagrad may not do well on changing data)
	+ static oracle
	+ greedy parser
	+ beam parser: still has memory issues
	= feature select.

	* INFO:
	+ biyofiz gpu memory is sufficient for nbeam*nbatch*ncpu <= 10000

	julia> @time b42y=KUparser.bparse(dev,net,feats,100,5,20);
	elapsed time: 261.986853539 seconds (3 MB allocated)
	julia> @time b41y=KUparser.bparse(dev,net,feats,10,50,20);
	elapsed time: 32.315438529 seconds (3 MB allocated)
	julia> find(b41y .!= b42y)
	1-element Array{Int64,1}:
	1324

	+ beam parser gives better head score with same model:

	julia> gold=map(x->x.head, dev);
	julia> mean(vcat(gold...) .== vcat(g0...))
	0.9105865343869183
	julia> mean(vcat(gold...) .== vcat(b41y...))
	0.9154473165989481

	* TODO: src/bparser.jl: minibatch version:
        x do not keep computing costs for finished sentences: too minor
        x do all beam elements finish simultaneously?
        x cache cost in parser?
	x repeated states on the beam?
	= nbeam=10 and nbeam=100 give the same parse?
	== in all except sent 1324. beam1 vs beam10 differ in 224 sentences.

	* test/timing.jl: minibatch version speed test:

	# Greedy parser
	g0=KUparser.gparse(dev,gnet,feats)		elapsed time: 148.237107122 seconds
	g1=KUparser.gparse(dev,gnet,feats,1700)		elapsed time: 22.188889154 seconds
	g2=KUparser.gparse(dev,gnet,feats,1700,20)	elapsed time: 8.051600384 seconds
	g3=KUparser.gparse(dev,gnet,feats,100)		elapsed time: 26.318353452 seconds
	g4=KUparser.gparse(dev,gnet,feats,100,20)	elapsed time: 8.062792516 seconds

	# These are with beam size 1
	# Final parses same as g0
	b0=KUparser.bparse(dev,gnet,feats,1)		elapsed time: 156.000890758 seconds
	b1=KUparser.bparse(dev,gnet,feats,1,1700)	elapsed time: 30.145607698 seconds
	b2=KUparser.bparse(dev,gnet,feats,1,1700,20)	elapsed time: 8.18903106 seconds
	b3=KUparser.bparse(dev,gnet,feats,1,100)	elapsed time: 31.510566003 seconds
	b4=KUparser.bparse(dev,gnet,feats,1,100,20)	elapsed time: 8.234869093 seconds

	# These are with beam size 10 on the first 100 sentences of dev:
	# Final parses not same with g0[1:100]
	b01=KUparser.bparse(dev[1:100],gnet,feats,10)		elapsed time: 25.057099378 seconds
	b11=KUparser.bparse(dev[1:100],gnet,feats,10,100)	elapsed time: 14.705737159 seconds
	b21=KUparser.bparse(dev[1:100],gnet,feats,10,100,20)	elapsed time: 5.154158539 seconds
	b31=KUparser.bparse(dev[1:100],gnet,feats,10,10)	elapsed time: 16.469459534 seconds
	b41=KUparser.bparse(dev[1:100],gnet,feats,10,10,20)	elapsed time: 5.161457464 seconds

	# These are with beam size 100 on the first 100 sentences of dev:
	# Final parses same as b01
	b02=KUparser.bparse(dev[1:100],gnet,feats,100)		elapsed time: 137.201635533 seconds
	b12=KUparser.bparse(dev[1:100],gnet,feats,100,100)	elapsed time: 132.684041541 seconds
	b22=KUparser.bparse(dev[1:100],gnet,feats,100,100,20)	elapsed time: 18.501004294 seconds
	b32=KUparser.bparse(dev[1:100],gnet,feats,100,10)	elapsed time: 132.337806865 seconds
	b42=KUparser.bparse(dev[1:100],gnet,feats,100,10,20)	elapsed time: 18.514346591 seconds


2015-03-13  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/bparser.jl: speed test:

	# Time for greedy parser on 1700 sentence dev
	julia> @time g=KUparser.gparse(dev,gnet,feats);
	elapsed time: 149.497789522 seconds (4116 MB allocated, 1.06% gc time in 189 pauses with 0 full sweep)

	# Time for beam parser on same data with beam=1
	julia> @time b=KUparser.bparse(dev,gnet,feats,1);
	elapsed time: 159.778490775 seconds (7173 MB allocated, 3.76% gc time in 328 pauses with 9 full sweep)

	# Time on dev[1:100]
	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,1);
	elapsed time: 9.962360704 seconds (440 MB allocated, 5.42% gc time in 20 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,5);
	elapsed time: 16.47657518 seconds (1940 MB allocated, 8.55% gc time in 89 pauses with 2 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,10);
	elapsed time: 27.863031912 seconds (3773 MB allocated, 12.66% gc time in 172 pauses with 6 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,50);
	elapsed time: 84.229235102 seconds (17997 MB allocated, 18.13% gc time in 806 pauses with 25 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,100);
	elapsed time: 158.230640377 seconds (35313 MB allocated, 16.89% gc time in 1549 pauses with 41 full sweep)

	# Time tests with ncpu=20

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,1,20);
	elapsed time: 9.237851461 seconds (2 MB allocated)
	elapsed time: 9.766501577 seconds (107 MB allocated, 4.21% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,5,20);
	elapsed time: 9.447347633 seconds (2 MB allocated)
	elapsed time: 9.975221305 seconds (107 MB allocated, 4.11% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,10,20);
	elapsed time: 13.658449233 seconds (2 MB allocated)
	elapsed time: 14.184126282 seconds (107 MB allocated, 2.89% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,50,20);
	elapsed time: 15.286421047 seconds (2 MB allocated)
	elapsed time: 15.809166647 seconds (107 MB allocated, 2.60% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,100,20);
	elapsed time: 27.447839359 seconds (2 MB allocated)
	elapsed time: 28.380576273 seconds (107 MB allocated, 2.96% gc time in 5 pauses with 2 full sweep)


2015-03-12  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO: src/bparser.jl:
	+ early stop?  could implement by copying into big x
	+ mincost may not be 0 for non-planar sentences
	= sortperm! suggest AbstractArray to julia
	= Now we sort the nc candidates and copy top np back to the beam
	x softperm! may not be necessary when nc <= beam (unless we care about the first candidate being the best)
	= do we need features when we have 0 or 1 valid move?
	= do not return y from gparser, return x,z consistently from each method
	x maybe have optional trn struct and return trn.x trn.y trn.nx
	x check for identical states on the beam: score will be difft

2015-03-08  Deniz Yuret  <dyuret@ku.edu.tr>

	* Speed-test:

	julia@iui> @time KUparser.gparse(trn, net, feats, 2000, 20);
	elapsed time: 40.50693341 seconds (9502 MB allocated, 8.38% gc time in 14 pauses with 11 full sweep)
	elapsed time: 86.205662824 seconds (107430 MB allocated, 6.12% gc time in 86 pauses with 14 full sweep)

	julia@bio> @time KUparser.gparse(trn, net, feats, 500, 20);
	elapsed time: 75.61331844 seconds (9476 MB allocated, 3.19% gc time in 8 pauses with 6 full sweep)
	elapsed time: 112.552530706 seconds (107352 MB allocated, 4.21% gc time in 75 pauses with 9 full sweep)

	julia3@ilac> @time KUparser.gparse(trn, net, feats, 1700, 12);
	elapsed time: 86.231203 seconds (11419169336 bytes allocated, 7.88% gc time)
	elapsed time: 123.933778 seconds (75581738656 bytes allocated, 16.60% gc time)

2015-03-05  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	= write bparser
	= real use of rnn's is to map text to meaning!

	= should we try parallel for?
	= see how SharedArray is implemented and use it for net weights: x is bigger!

	* src/gparser.jl: gpu minibatch version:

	# dev has 1700 sentences and 40117 words
	# fastest matlab test speed was 26 sents/sec = 1.6298 ms/word
	# fastest matlab dump speed was 30 sents/sec = 1.4125 ms/word
	# fastest julia test speed is 80 sents/sec = 0.5286 ms/word
	# fastest julia dump speed is 116 sents/sec = 0.3652 ms/word

	# 3.6986 ms/word: parsing sentences one at a time
	include("fooparser.jl")
	julia> @time h2=KUparser.gparse(dev, n, Feats.fv021a);
	elapsed time: 148.37933571 seconds (4145 MB allocated, 0.83% gc time in 190 pauses with 0 full sweep)

	# 0.5286 ms/word: parsing sentences in minibatches
	julia> @time h1=KUparser.gparse(dev, n, Feats.fv021a, 1700);
	elapsed time: 21.206189373 seconds (6355 MB allocated, 8.16% gc time in 273 pauses with 1 full sweep)

	# 0.3652 ms/word: everything except KUnet prediction
	julia> @time h0=KUparser.gparse(dev, n, Feats.fv021a, false);
	elapsed time: 14.648858577 seconds (3488 MB allocated, 5.64% gc time in 160 pauses with 0 full sweep)

	# For training with Julia I expect 8 mins to parse, 2 mins to
	update, 10 mins per epoch.

2015-03-04  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/features.jl:
	> @time foo=KUparser.gparse(dev[1:100], n, Feats.fv021a); # with rand!
	> elapsed time: 0.899239837 seconds (212 MB allocated, 4.95% gc time in 9 pauses with 0 full sweep)

	= Better but still allocating, why?

	> @time foo=KUparser.gparse(dev[1:100], n, Feats.fv021a); # with predict
	> elapsed time: 9.124658661 seconds (254 MB allocated, 0.79% gc time in 11 pauses with 0 full sweep)

	* features.jl: get rid of avec allocation.
	* net.jl: find what allocates 6kb?

2015-03-03  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	= get rid of allocation
	= optimize feature extraction
	x cuda parser?
	x solve pmap problem (shared arrays, pointers?)

	* timing: dev is the 1700 sentences:
	sent_pct: 0.5888
	head_pct: 0.0894
	word_pct: 0.0785
	move_pct: 0.0340

	We are doing about 11 sentences/second: (90ms/sent)

	julia> @time foo=KUparser.gparse(dev[1:10], net, Fmats.fv021a)
	elapsed time: 1.078577283 seconds (65 MB allocated, 0.85% gc time in 3 pauses with 0 full sweep)
	julia> @time foo=KUparser.gparse(dev[1:100], net, Fmats.fv021a);
	elapsed time: 9.161665507 seconds (557 MB allocated, 0.80% gc time in 25 pauses with 0 full sweep)
	julia> @time foo=KUparser.gparse(dev, net, Fmats.fv021a);
	elapsed time: 152.361663243 seconds (9084 MB allocated, 1.26% gc time in 415 pauses with 0 full sweep)

	The feature construction is actually pretty fast: (10ms/sent)

	After replacing "predict" with "rand":
	julia> @time foo=KUparser.gparse(dev[1:100], net, Fmats.fv021a);
	elapsed time: 1.007098236 seconds (510 MB allocated, 11.25% gc time in 23 pauses with 0 full sweep)

	However there is too much allocation and speed can be improved.

	More impact would be to batch sentences first.

2014-10-27  Deniz Yuret  <dyuret@ku.edu.tr>

	* run_static_dynamic_1023_archybrid_conllWSJToken_wikipedia2MUNK_100_fv021a_0_333140404105682_ilac.out:
	First two epochs identical to 1017 run.  For conll07 use the 2014-10-10 result.
	:(copied from vectorparser/ChangeLog)

		stat_pct		move_pct	      	head_pct	      	word_pct
	epoch	trn	dev	tst	trn	dev	tst   	trn	dev	tst   	trn	dev	tst
	1	0.0142	0.0329	0.0346	0.0203	0.0409	0.0423	0.0590	0.1081	0.1134	0.0509	0.0946	0.0983
	2	0.0138	0.0376	0.0389	0.0136	0.0373	0.0374	0.0400	0.0994	0.1023	0.0359	0.0881	0.0912
	3	0.0102	0.0364	0.0380	0.0081	0.0351	0.0355	0.0269	0.0934	0.0969	0.0246	0.0832	0.0860
	4	0.0088	0.0361	0.0378	0.0058	0.0348	0.0352	0.0209	0.0921	0.0955	0.0193	0.0819	0.0845
	5	0.0076	0.0360	0.0376	0.0043	0.0342	0.0349	0.0174	0.0910	0.0950	0.0162	0.0810	0.0839
	6	0.0071	0.0359	0.0375	0.0033	0.0341	0.0347	0.0150	0.0907	0.0940	0.0142	0.0807	0.0835
	7	0.0068	0.0359	0.0374	0.0025	0.0336	0.0346	0.0131	0.0894	0.0940	0.0123	0.0795	0.0835
	8	0.0067	0.0360	0.0374	0.0023	0.0336	0.0343	0.0125	0.0892	0.0934	0.0118	0.0792	0.0832
	9	0.0068	0.0359	0.0377	0.0023	0.0333	0.0342	0.0125	0.0888	0.0935	0.0119	0.0789	0.0833
	10	0.0068	0.0358	0.0376	0.0021	0.0333	0.0342	0.0121	0.0885	0.0933	0.0116	0.0786	0.0830
	11	0.0068	0.0360	0.0377	0.0021	0.0335	0.0341	0.0120	0.0891	0.0928	0.0116	0.0792	0.0827
	12	0.0068	0.0361	0.0378	0.0021	0.0335	0.0341	0.0119	0.0889	0.0925	0.0116	0.0790	0.0824
	13	0.0068	0.0359	0.0379	0.0020	0.0332	0.0339	0.0117	0.0884	0.0920	0.0114	0.0785	0.0821
	14	0.0069	0.0359	0.0380	0.0020	0.0333	0.0340	0.0116	0.0888	0.0921	0.0112	0.0788	0.0823
	15	0.0068	0.0360	0.0380	0.0019	0.0334	0.0340	0.0115	0.0888	0.0920	0.0111	0.0787	0.0820
	16	0.0068	0.0364	0.0380	0.0019	0.0338	0.0340	0.0116	0.0899	0.0919	0.0113	0.0798	0.0820
	17	0.0069	0.0364	0.0379	0.0019	0.0337	0.0340	0.0114	0.0898	0.0918	0.0110	0.0799	0.0819
	18	0.0069	0.0363	0.0380	0.0018	0.0336	0.0341	0.0115	0.0894	0.0922	0.0110	0.0795	0.0823
	19	0.0069	0.0365	0.0380	0.0018	0.0336	0.0341	0.0115	0.0893	0.0921	0.0109	0.0795	0.0822
	20	0.0069	0.0364	0.0380	0.0017	0.0337	0.0342	0.0113	0.0894	0.0927	0.0108	0.0796	0.0827

2014-10-10  Deniz Yuret  <dyuret@ku.edu.tr>

	* conll07-dev: trn/dev/tst results (copied from vectorparser/ChangeLog)
	run_static_dynamic_1005_archybrid_conll07EnglishToken_wikipedia2MUNK_100_fv019_0_372063662109375_.out
	run/log2table.pl: extract table from log file:
	run/log2table.pl head_pct run_static_dynamic_1005_archybrid_conll07EnglishToken_wikipedia2MUNK_100_fv019_0_372063662109375_.out

	epoch	trn	dev	tst
	1	0.0644	0.1442	0.1455
	2	0.0408	0.1318	0.1403
	3	0.0211	0.1258	0.1317
	4	0.0148	0.1240	0.1305
	5	0.0108	0.1233	0.1269
	6	0.0087	0.1231	0.1267
	7	0.0073	0.1224	0.1235
	8	0.0065	0.1223	0.1235
	9	0.0063	0.1225	0.1235
	10	0.0060	0.1214	0.1219
	11	0.0060	0.1216	0.1219
	12	0.0056	0.1211	0.1201
	13	0.0056	0.1212	0.1219
	14	0.0055	0.1214	0.1221
	15	0.0053	0.1210	0.1217
	16	0.0052	0.1206	0.1229
	17	0.0050	0.1202	0.1241
	18	0.0050	0.1202	0.1243
	19	0.0048	0.1200	0.1239
	20	0.0049	0.1199	0.1251

2014-10-16  Deniz Yuret  <dyuret@ku.edu.tr>

	* Best points: (copied from vectorparser/ChangeLog)

	corpus: conllWSJToken (trn02-21:39832s,950028w,1820392m;dev22:1700s,40117w,76834m;tst23:2416s,56684w,108536m)
	arctype: archybrid (TODO: can archybrid13 be the same?)
	embedding: wikipedia2MUNK-100
	feats: fv021a
	kernel: rbf
	gamma: 0.333140404105682
	devscore: 0.0325506937033084 (nsv=96326, single=0.0328500403467215)
	test: (TODO)

	corpus: conll07EnglishToken (trn:16588s,398439w,763702m;dev:1989s,48134w,92290m;trn+dev:18577s,446573w,855992m;tst:214s,5003w)
	arctype: archybrid
	embedding: wikipedia2MUNK-100 (TODO: other embeddings, bansal)
	feats: fv022b (TODO: compare with wsj feats)
	kernel: rbf
	gamma: 0.376747095368119
	tstscore: 0.0418668 (1-epoch full-trn/tst, nsv=57661)
	test: (TODO: debug run_static_dynamic)
