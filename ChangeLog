2015-04-06    <dyuret@ku.edu.tr>

	* test/fselect.jl: FEATURE SELECTION EXPERIMENTS

	corpus: c07, a11
	parser: ArcEager13, ArcHybrid13
	eager-all: eager39, eager64
	eager-start: eager39, eager36, eager21, eager20
	hybrid-all: hybrid54
	hybrid-start: hybrid13, hybrid14, hybrid28
	:rename acl11eager->eager39, tacl13hybrid->hybrid13.

	Results:

	fs07h54h28: h28=8683 -> h28b=8797 (04081831-fs07h54h28.cache)
	fs07h54h13: h13=8613 -> h14=8791 (04050753-hybrid54.cache) ok

	fs07e39e39: e39=8619 -> e36=8725 (04060625-fs07e39e39.cache) ok
	fs07e39e21: e21=8623 -> e20b=8705 (04072145-fs07e39e21.cache) ok
	fs07e64e20: e20=8613 -> e21b=8677 (04080348-fs07e64e20c.cache) ok

	fs11h54h28: h28=8978 -> h27@64=8997 (04071554-fs11h54h28.cache) ok
	fs11h54h14: h14=8931 -> h22?@107=8973... @@480377@fselect (fs11h54h14.cache) we should try hybrid on acl11. ) start: h14=8931 curr15@5=8931 30m/f.

	fs11e64e20: e20=8926 -> e20=8926 (04071209-fs11e64e20.cache) ok
	fs11e39e21: e21=8880 -> e23=8906 (04061344-a11e21.cache) ok
	fs11e39e39: e39=8906 -> e39=8906 (04042125-acl11eager2.cache) ok

2015-04-05    <dyuret@ku.edu.tr>

	* Summary: corpus-parser-arctype-feats where:
	corpus in acl11, con07
	parser in beam, dynamic, static
	arctype in hybrid, eager
	feats in ZN11e (arc11eager), GN13h (tacl13hybrid), or other

	acl11-beam64-eager-ZN11e: uas1:no uas2:no
	:(only ZN11 scores exclude punct)
	uas2dev	uas2tst	exp	las2dev	las2tst	uem2dev	uem2tst
	9314	9290	ZN11	x	9180	5012	4800
	9212	9165	03290018-bparse64.out(113/166)
	9211	9171	03220927-bparselatestop.out(129/207)
	9205	9166	03220548-bparsedbg.out(193/256)
	9186	9136	03201925-julia3_btrain_jl.out(77/77)
	9171	9152	03292013-bp10acl11eager.out(55/115)
	9167	9153	04022337-bp64a11eR1.out(55/110) trn:7m30s prs:96m epoch:27m (5t1p)
	9159	9142	03300736-bp10acl11eager13.out(75/155)
	9158	9145	03240436-bpacl11.out(79/256)
	9158	9140	03192351-gparsedbg.out(194/256)
	9156	9141	04030908-bp64a11e13.out(65/130) trn:7m30s prs:96m epoch:27m (5t1p)
	9154	9129	03171146-julia3_gtrain_jl.out(93/127)
	9136	9109	03212217-gpacl11.out(184/256)
	9130	9137	bp64a11h27.out(20/?)... @@parcore@test (feats=hybrid27) ~60m/epoch
	9129	9146	bp64a11e20.out(42/?)... @@3999@iui@test (feats=eager20) ~30m/epoch
	9116	9074	03200328-oparsedbg.out(254/256)
	9099	9075	03160543-julia3_otrain_jl.out(128/256)
	9093	9060	03212217-opacl11.out(210/256)

	con07-dynamic-hybrid-GN13h: uas1:ok uas2:ok
	:(no averaging or dev set in my results)
	uas	las	exp
	8762	8628	GN13
	8903	x	04061328-gp07h14.out(314/458) (feats=hybrid14)
	8827	x	03291208-gpconll07hybrid13.out(93/187)
	8811	x	04010424-gp07h13.out(164/328) (repeat of 03291208)
	8801	x	03292304-gpconll07hybrid3.out(226/453) (ArcHybridR1)
	8799	x	04010425-gp07h13d25.out(139/256) (dropout 0.2 0.5)
	8793	x	03210908-gpconll07.out(133/256) (fv022b, no deprel)
	8793	x	03311930-gp07h13k10.out(134/268) (10k hidden unit)
	8789	x	03270848-gptacl13wp.out(241/256) (all wp features)
	8789	x	03250401-gptacl13.out(169/213)
	8773	x	03271009-gptacl13.out(233/256)
	8761	x	04010123-gp07h13k44.out(138/276) (4k+4k hidden layers)
	8727	x	03260538-gptacl13nl.out(228/256) (no deprel)
	8717	x	03311154-gp07h13d25.out(16/32) (dropout 0.2 0.5, too short?)
	8709	x	03260132-gptacl13w.out(256/256) (only w features)
	8659	x	03261450-gptacl13nd.out(26/256) (no dropout)
	8005	x	03311801-gp07h13lr1.out(1/148) (learningRate=1.0)
	7877	x	03270146-gptacl13p.out(187/256) (only p features)

	con07-static-hybrid-GN13h: uas1:ok uas2:ok
	uas	las	exp
	8643	8496	GN13
	8887	x	04070512-op07h14.out(377/754) (feats=hybrid14)
	8823	x	03300624-opconll07hybrid13.out(242/485)
	8783	x	03282213-opconll07hybrid.out(79/159)
	8699	x	03210931-opconll07.out(170/256) (fv022b, no deprel)
	8689	x	03271008-optacl13.out(234/256)
	8675	x	03242000-optacl13.out(66/78)

	con07-beam10-hybrid-GN13h
	uas	las	exp
	8865	x	03221208-bpconll07.out(54/256)

	con07-dynamic-eager-ZN11e: uas1:no uas2:yes
	uas	las	exp
	8869	8769	GN13
	8897	x	...gp07e20.out(62/?) @@480422@test @@aws
	8843	?	04021402-gp07e13k44.out(95/190) (4+4k hidden)
	8839	?	04020644-gp07e13k10.out(39/100) (10k hidden)
	8823	?	04031246-gp07e13l01.out(190/380) (learningRate 0.1)
	8821	x	03292103-gpconll07eager13.out(93/187)
	8817	x	04062220-gp07e36.out(71/100) (feats=eager36)
	8803	x	...gp07e20b.out(44/?) @@480423@test
	8799	x	03290106-gpconll07eager.out(22/45)
	8795	?	04021040-gp07e13d25.out(32/100) (dropout 0.2 0.5)
	8785	?	04021101-gp07e13.out(33/100) (repl 03292103)
	8763	x	03281848-gpconll07eager.out(32/65)
	?	?	gp07e21.out... @@480424@test
	?	?	gp07e21b.out... @@480425@test
	?	?	gp07e23.out... @@480426@test
	?	?	gp07e36.out... @@480427@test
	?	?	gp07e39.out... @@480428@test

	con07-static-eager-ZN11e: uas1:ok uas2:no
	uas	las	exp
	8610	8493	GN13
	8685	x	03281640-opconll07eager.out(21/43)
	8681	x	03300220-opconll07eager13.out(102/139)
	8675	x	04070709-op07e36.out(28/100) (feats=eager36)
	8649	x	03292324-opconll07eager.out(31/63)


	* 04050753-hybrid54.cache: optimizing ArcHybrid13 features on conll07.

	tacl13hybrid	.8613	n0lp n0p      n0w n1p n1w     s0lp s0p s0rp s0w     s1lp s1rp s1p s1w
	hybrid14	.8791	n0lp     n0lw n0w n1p n1w s0d s0lp s0p s0rp s0w s1B s1lp      s1p s1w

	0.06356	s0w	0.01439	s0p	0.01119	+n0p
	0.06276	n1w	0.01279	s0rp	0.00080	+s1rp
	0.05737	n0w	0.01199	s0d*	
	0.02319	s1w	0.01199	n1p	
	0.01959	s1B*	0.00999	n0lw*	
	0.01659	n0lp	0.00979	s1p	
	0.01519	s0lp	0.00919	s1lp	

	* 04042125-acl11eager2.cache: unfortunately we cannot beat the
	original feature set with single step moves:

	acl11eager(39)	.8906
	best38		.8899

	But we do have a ranking of all 39 features by how much their
	removal effects performance:

	0.03849	n0w	0.00394	s0L	0.00307	n2w	0.00232	s0rw	
	0.02894	s0w	0.00394	s0B	0.00284	s0h2w	0.00197	n0l2w	
	0.02445	n1w	0.00364	n0lL	0.00282	s0lL	0.00162	s0rp	
	0.00678	s0p	0.00359	s0r2p	0.00274	s0rL	0.00160	n0lp	
	0.00481	s0l2p	0.00359	s0hw	0.00257	s0hp	0.00157	s0hL	
	0.00439	n1p	0.00359	n0A	0.00252	n0l2L	0.00112	s0r2w	
	0.00436	s0h2p	0.00354	s0lp	0.00244	s0A	0.00080	n0l2p	
	0.00416	n2p	0.00327	s0r2L	0.00237	s0d	0.00072	s0lw	
	0.00409	s0l2L	0.00327	s0l2w	0.00237	n0a	0.00067	n0lw	
	0.00401	n0p	0.00317	s0a	0.00234	s0b	

	+ do we have overfitting because of no dropout (s0l2p?, s0h2p?)
	+ should we try features of s1?

	* 04050905-acl11eager.cache: stopped early, same result as acl11eager2.


2015-04-03    <dyuret@ku.edu.tr>

	* fselect: feature selection.  up to ncpu=6 and pbatch=500 can be
	supported on ilac with acl11eager (700MB per cpu).  TODO: feature
	set for archybrid.

 480368 0.50531 hybrid54   dyuret       r     04/03/2015 23:02:25 ilac.q@ilac-0-3.local              1        
 480370 0.50531 acl11eager dyuret       qw    04/03/2015 23:04:42                                    1        
   3969 0.60500 acl11eager2 dyuret       r     04/03/2015 23:07:22 iui.q@iui-5-0.local                1        

2015-04-02    <dyuret@ku.edu.tr>

	* Latex-table:

	ref	parser		feats		corpus	ref-uas		ku-uas1		ku-uas2
	GN13	hybrid:static	hybrid13	conll07	.8643		.8823		?
	GN13	hybrid:dynamic	hybrid13	conll07	.8762		.8827		?
	GN13	eager:static	eager39		conll07	.8610		.8685		?
	GN13	eager:dynamic	eager39		conll07	.8869		.8821		?
	ZN11	eager:beam	eager39		ptb12	.9290		.9225		?
	MCP05	mst1?		?		?	.9090		?		?
	MP06	mst2,proj2?	?		?	.9150		?		?
	E96	proj1/2?	?		?	?		?		?
	C07	proj2+?		?		conll07	.9063		?		?
	KC10	order3?		?		?	.9304		?		?
	KCC08	semisup08?	?		?	.9316		?		?
	SICC09	semisup09?	?		?	.9379		?		?
	SIN11	semisup11?	?		?	.9422		?		?
	BGL14	mst2/wvec?	?		?	.9269		?		?

	Corpus questions: which converter?  which set of deprels?
	Graph parsing variants: projective vs mst?  order?  semisupervised?
	[GN13] Yoav Goldberg and Joakim Nivre. 2013. Training Deterministic Parsers with Non-Deterministic Oracles. TACL, vol 1, pp 403--414.
	[ZN11] Yue Zhang and Joakim Nivre. 2011. Transition-based Dependency Parsing with Rich Non-local Features. In ACL '11.
	[MCP05] Ryan McDonald, Koby Crammer and Fernando Pereira. 2005. Online Large-Margin Training of Dependency Parsers. In ACL '05.
	[MP06] Ryan T McDonald and Fernando CN Pereira. 2006. Online Learning of Approximate Dependency Parsing Algorithms. In EACL '06.
	[KC10] Koo, Terry, and Michael Collins. Efficient third-order dependency parsers. ACL '10.
	[KCC08] Koo, Terry, Xavier Carreras, and Michael Collins. Simple Semi-supervised Dependency Parsing. In ACL '08.
	[SICC09] Suzuki, Jun, et al. An empirical study of semi-supervised structured conditional models for dependency parsing. In EMNLP '09.
	[SIN11] Suzuki, Jun, Hideki Isozaki, and Masaaki Nagata. Learning condensed feature representations from large unsupervised data sets for supervised learning. In ACL '11.
	[C07] Carreras, Xavier. Experiments with a Higher-Order Projective Dependency Parser. EMNLP '07.
	[E96] Jason Eisner. 1996. Three new probabilistic models for dependency parsing. In COLING-96
	[BGL14] Mohit Bansal, Kevin Gimpel and Karen Livescu. 2014. Tailoring Continuous Word Representations for Dependency Parsing. ACL '14.

2015-04-01    <dyuret@ku.edu.tr>


2015-03-31    <dyuret@ku.edu.tr>

	* TODO:
	- experiment with shuffling the training data.
	- figure out eval.pl vs discounting punct pos for acl11.
	- figure out fixed epoch vs dev set for conll07.
	- should we not use bparser during fselect?

	- Leave postags as postags, compare with context vectors.

	- Try the split experiment with three networks (move, rlabel, llabel).

	- Explore training options.
	-- Try move+label nnet output?
	-- cost function of nnet, cost fn of parser?

	- Run five experiments and report avg-std.

	- Explore feature options.
	  training epoch timing: conll07-tacl13hybrid: 120s, conll07-acl11eager: 220s, acl11-acl11eager: 448s
	  tacl13hybrid has 13 features: [(s0,s1,n0,n1)(wp),(s1l,s1r,s0l,s0r,n0l)(p)]
	  acl11eager has 39: [n0(wpAa),s0(wpLdAaBb),(n1,n2,s0h2)(wp),(n0l2,n0l,s0h,s0l2,s0l,s0r2,s0r)(wpL)]
	  Nobody has heads in hybrid, si may have heads in eager.
	  In both si have children, but only n0l in buffer.
	  s1 is important in hybrid, so we should add its children.
	  we should subtract heads and labels for all si,ni for hybrid.  So we have 54:
	  hybrid54: [n0(wpAa),(s0,s1)(wpdAaBb),(n1,n2,s2)(wp),(n0l2,n0l,s0l2,s0l,s0r2,s0r,s1l2,s1l,s1r2,s1r)(wpL)]
	  our previous best feature sets:
	  fv021a: [n0(wpa),s0(wpb-),(s1,s0r)(wb),(n1,n0l)(wp),s2(w),s0l(wpb),(s1r,s2r)(a)]
	  fv022b: [n0(wpa),s0(wpabH),s1(wpbdH),(n1,n0l)(wp),(s0r,s0l)(w),(s1l)(pb),(s2)(W)]

	  For conll07/acl11 hybrid: start with tacl13hybrid or fv022b, do a search within hybrid54.
	  For conll07/acl11 eager : start with acl11eager and do a search within (maybe add s1?)
	  Each one level search means trying out 40-50 features.
	  Per epoch is 100min for 120s, 180min for 220s, 360min for 448s.
	  To finish one level in 24 hours we can do 14 epochs for 100min, 8 epochs for 180min, 4 epochs for 460 min.

	- Write paper.

	* Renames:
	Fmats -> Flist
	Features -> Fvec
	ArcEager -> ArcEagerR1
	ArcHybrid -> ArcHybridR1

	* iui-k40-memory: Each K40 has 11.5GB for a total of 23GB.  The
	ZN11 setup takes in MB GPU memory:
	  280*ncpu+0.1*ncpu*nbeam*nbatch
	For ncpu=20, nbeam=64, nbatch=128 we hit the upper limit.


2015-03-29  Deniz Yuret  <dyuret@ku.edu.tr>

	* memory: Right now we spend four times the memory we need during
	parsing to store the patterns for oparse.  This means we cannot
	oparse in iui-5-0 with 1.8m moves, 2565 dims = 10k per x makes 18G
	x matrix and 4 times that does not fit in the 64GB memory.  We
	were already thinking of making x and y optional for parsers, so
	we should implement that with pre-allocation.  Started working on
	oparse.

2015-03-28  Deniz Yuret  <dyuret@ku.edu.tr>

	* archybrid13.jl: This is identical to the GN13 implementation.
	$$480169 0.50531 gpconll07h dyuret       r     03/28/2015 23:56:10 ilac.q@ilac-3-1.local              1        
gpconll07hybrid13.out
DATA:	1	0.8441778	0.8279033
DATA:	2	0.83230513	0.8199081
DATA:	4	0.86308396	0.84029585
DATA:	8	0.8854879	0.8484909
DATA:	16	0.9092243	0.85968417
DATA:	32	0.9319865	0.8678793
DATA:	64	0.95570713	0.86927843
DATA:	93	0.96766937	0.8826704	***
DATA:	110	0.9719262	0.8754747

	$$480170 0.50531 opconll07h dyuret       qw    03/28/2015 23:56:36                                    1        
opconll07hybrid13.out
DATA:	1	0.84368515	0.82670397
DATA:	2	0.85893685	0.8372976
DATA:	4	0.8764592	0.84829104
DATA:	8	0.89386505	0.8514891
DATA:	16	0.9144238	0.856686
DATA:	32	0.93653667	0.8646812
DATA:	64	0.9596527	0.871677
DATA:	90	0.969781	0.87687385	***
DATA:	104	0.9736997	0.87227666

	* arceager13.jl: This is identical to the GN13 implementation.
	$$480168 0.50531 bp10acl11e dyuret       qw    03/28/2015 22:10:05                                    1        
bp10acl11eager13.out
DATA:	5	0.91694665	0.89882094	0.894397
DATA:	10	0.93207145	0.9077448	0.9059699
DATA:	15	0.94179016	0.9104121	0.90847504
DATA:	20	0.9500162	0.9124311	0.9120034
DATA:	25	0.95625395	0.9119825	0.9115447
DATA:	30	0.9611717	0.91415113	0.91249734	***
DATA:	35	0.9651421	0.9134033	0.9133265

	$$480171 0.00000 gpconll07e dyuret       qw    03/29/2015 00:13:46                                    1        
gpconll07eager13.out
DATA:	1	0.8377936	0.82230663
DATA:	2	0.8526624	0.8237058
DATA:	4	0.88646203	0.85088944
DATA:	8	0.91018265	0.86128324
DATA:	16	0.9358134	0.87207675
DATA:	32	0.9612292	0.87327605
DATA:	39	0.9680746	0.8786728	***
DATA:	53	0.9765279	0.8772736

	$$480172 0.00000 opconll07e dyuret       qw    03/29/2015 00:13:48                                    1        

	+bp10acl11eager13.out
	+bp10acl11eager.out
	+bparse64.out
	+gpconll07eager13.out: out of memory
	+gpconll07eager.out
	+gpconll07hybrid13.out
	+gpconll07hybrid3.out
	+opconll07eager13.out: out of memory
	+opconll07eager.out: crashed
	+opconll07hybrid.out

	* testbparser2.jl: Time and space for ZN11

	Space: Need ncpu x pbatch x nbeam < 7680 to fit in K20 memory
	ncpu	pbatch	nbeam	mem/cpu	acl11dev
	12	30	10	305MiB	80 secs (including 15 secs cpu initialization)
	12	40	10	310MiB	76 secs
	12	50	10	325MiB	72 secs
	12	10	64	335MiB	267 secs
	12	64	10	335MiB	72 secs
	12	80	10	350MiB	69 secs
	12	100	10	365MiB	69 secs
	12	128	10	390MiB	out of memory (this is when proc1 has 277MiB, it has more like 700 during training)

	Timing oparse: 0.07ms/w = 66s/epoch
	Timing KUnet.train: 2565x20000x24 net, 950028 words, 290s/epoch = 5mins
	!!! actually this is 448 seconds with dropout and adagrad ~ 8mins
	Timing nbeam=10: 1.5ms/w = 1425s/epoch = 24mins
	Timing nbeam=64, 6.3ms/w = 5985s/epoch = 100mins

	Recommended: ncpu=12, pbatch=32 (to be on the safe side), nbeam=10, pepochs=5.
	This will give us 5 epochs in 50 mins or 10 mins/epoch.
	- Maybe we should try learningRate=1 to speed things up?
	- They are using nbeam=64 we are using nbeam=10
	+ acleager is not identical to acleager13

	$$480162 0.50531 bp10acl11e dyuret       r     03/28/2015 19:31:40 ilac.q@ilac-2-0.local              1        
bp10acl11eager.out
DATA:	5	0.9163362	0.8975497	0.8949086	with punct
	5	0.9237522	0.9075777	0.9035607	*** (.9314 .9290 in ZN11 nopunct nbeam=64)
DATA:	10	0.9329146	0.90821844	0.90727544
DATA:	15	0.94265956	0.9111599	0.90988636
DATA:	20	0.95063406	0.9124062	0.9129384
DATA:	25	0.95681393	0.91447514	0.9135206
DATA:	30	0.96161795	0.91464967	0.9138205
DATA:	35	0.96584314	0.91492385	0.9137323
DATA:	40	0.9688472	0.9163198	0.91383815
DATA:	45	0.97186923	0.9169928	0.9142968	***
DATA:	50	0.97418284	0.915198	0.9141733

	* GN13: comparison using labeled parsers (cont. 2015-03-25)
	+ using exact feature sets acl11eager and tacl13hybrid as far as I know
	+ still not using exact archybrid13 and arceager13
	- still not using a dev set to determine when to quit
	- still not taking averages
	- still no easyfirst
	- try much larger learningRate (lr=1 worked well during debugging with conll07.tst)

	* 03281848-gpconll07eager.out:
	$$480149 0.50531 gpconll07e dyuret       r     03/28/2015 12:02:55 ilac.q@ilac-2-0.local              1        
DATA:	1	0.8374577	0.82490504
DATA:	2	0.84297526	0.8139117
DATA:	4	0.8828344	0.8454927
DATA:	8	0.9080867	0.8538877
DATA:	16	0.93488634	0.8694783
DATA:	32	0.96121573	0.8762742	*** (.8869 in GN13)
DATA:	64	0.98047125	0.8686788
DATA:	65	0.98105574	0.8712772

	* 03290106-gpconll07eager.out: Second run:
	$$480164 0.50531 gpconll07e dyuret       r     03/28/2015 20:31:40 ilac.q@ilac-3-0.local              1        
DATA:	1	0.8370031	0.8173096
DATA:	2	0.8489071	0.81690985
DATA:	4	0.8842317	0.85048974
DATA:	8	0.90986246	0.8630822
DATA:	16	0.93509233	0.86727965
DATA:	22	0.9471867	0.8798721	*** (.8869 in GN13)
DATA:	32	0.95996624	0.87807316
DATA:	45	0.971288	0.87227666

	* 03281640-opconll07eager.out:
	$$480150 0.50531 opconll07e dyuret       r     03/28/2015 12:11:55 ilac.q@ilac-2-1.local              1        
DATA:	1	0.8356036	0.82290626
DATA:	2	0.8547718	0.8237058
DATA:	4	0.87467223	0.8374975
DATA:	8	0.8972889	0.8518889
DATA:	16	0.9231615	0.8620828
DATA:	21	0.9355335	0.8684789	*** (.8610 in GN13)
DATA:	32	0.9519026	0.85748553
DATA:	43	0.96290195	0.85968417

	Second run: opconll07eager.out
	##480165 0.50531 opconll07e dyuret       r     03/28/2015 20:33:10 ilac.q@ilac-3-1.local              1        
	$$480173 0.00000 opconll07e dyuret       qw    03/29/2015 00:15:41                                    1        	

	* 03282213-opconll07hybrid.out:
	$$480151 0.50531 opconll07h dyuret       r     03/28/2015 12:12:25 ilac.q@ilac-0-0.local              1        
DATA:	1	0.843506	0.8297022
DATA:	2	0.85940933	0.8392964
DATA:	4	0.87632257	0.8462922
DATA:	8	0.89458835	0.8496902
DATA:	16	0.9145694	0.85908455
DATA:	32	0.93615603	0.86707973
DATA:	64	0.96023047	0.86987805
DATA:	79	0.9661533	0.878273	*** (.8643 in GN13)
DATA:	128	0.9788523	0.8744753
DATA:	159	0.9828203	0.8746752

	$$480160 0.50531 gpconll07h dyuret       r     03/28/2015 18:58:10 ilac.q@ilac-2-1.local              1        
gpconll07hybrid3.out
DATA:	1	0.84406805	0.8257046	*** (.8762 in GN13)
DATA:	2	0.83588797	0.81571054
DATA:	4	0.8616822	0.838297
DATA:	8	0.88582385	0.8502898
DATA:	16	0.9098938	0.863282
DATA:	32	0.93317556	0.8674795
DATA:	64	0.9561214	0.875075
DATA:	128	0.9758696	0.8714771
DATA:	190	0.98406756	0.8794723	***
DATA:	194	0.98414147	0.8794723


2015-03-27  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/arceager.jl: Finished and tested arceager.  Passes the
	movecosts test.  However gives different results on 9 sentences of
	conll07.tst from archybrid.  Confirmed one to be non-projective.
	They may prefer different projectivizations.  However on sentence
	35 the errors are different, hybrid=3, eager=5.

	It turns out the default move ordering matters when oracle parsing
	corpora with nonprojective sentences.  Fixed the orders that gave
	the best results (LRS for hybrid, DLRS for eager).

	+ DEBUG. *julia*
	+ fix gparser.
	+ fix bparser.
	+ train.jl does not work with arceager. *ilac-julia*

	* src/parser.jl: BEST WAY TO REPRESENT PARSERS WITH COMMON FIELDS
	BUT DIFFERENT SETS OF MOVES

	I've been wrecking my brain to figure out the best way to do this
	in Julia.  We have a set of objects (parsers in my case), with
	common state elements and constructor (buffer, stack, a set of
	arcs etc.), but different move sets (arceager, archybrid etc. see
	this if interested).  Thus functions like validmoves(), move!()
	etc. are of several different types.  So far I have considered:

	1. Just define multiple composite types with different move()
	methods (pro), listing the same fields and constructor for
	each (con).

	2. Define a single "state" type that has the necessary fields and
	constructor (pro), include a "state" as a field in multiple
	composite types requiring double reference (con: i.e. you need to
	type parser.state.field instead of just parser.field).

	3. Put the list of (common) fields in a file and include this file
	in the definition of each composite type.  This prevents the
	problem of repeating the same code, but makes me a bit uneasy.  It
	also does not solve the constructor problem (I guess I can put the
	body of the constructors in a common file and include it, but that
	makes me even more uneasy).

	4. Have a single composite type with a field that indicates the
	"move policy".  Then have functions like validmoves(), move!()
	etc. branch on this move policy.  But that's just throwing away
	the beautiful function overloading machinery of Julia.

	5. Any solutions using parametric types, singleton types etc.?

	Best response from Simon Danisch:
	I'd vote for toivo's suggestion.
	So this could be a design:

	immutable Parser{Policy}
	common
	fields
	end

	#construction
	parser = Parser{:policy1}(...)
	#specialize the functions to a policy:
	validmove(::Parser{:policy1}) = ...
	validmove(::Parser{:policy2}) = ...
	#define functions for all parsers
	move!(::Parser) = ...

	To see what the interface is:

	gparser fields: nword (not necessary), nmove (could be a fn)
	gparser methods: features, anyvalidmoves, move!, movecosts, flen
	oparser fields: head and deprel (for debugging) nword, nmove (for init)
	oparser methods: same as gparser
	the list of p is returned, so its contents need to be accessible
	+ could have head and deprel as functions as well
	+ in fact probably best never to use fields
	all parsers need to take the "parser type" as an argument
	- make sure arceasy follows this pattern
	- implement nolabel versions as parser types as well
	bparser methods: same as gparser
	bparser fields: nmove
	arc!: head, deprel, lcnt, ldep, rcnt, rdep
	move!: nmove, sptr, wptr, stack
	validmoves: nmove, nword, wptr, sptr, L1, R1
	anyvalidmoves: wptr, sptr, nword
	movecosts: nword, nmove, wptr, sptr, stack, L1, R1

2015-03-26  Deniz Yuret  <dyuret@ku.edu.tr>

	* ZN11:
	> head stack features
	Yes they are not in the paper because they did not work well. Basically I try to extract features from the root of each sub tree.
	> encoding
	I treated lengths by capping them to 8. If I remember correctly, I did not do any  binning. They can be found at depparser_macros.h
	> set of labels
	Yes you can treat them as a vector. my implementation packed everything into a integer.

	+ Actuall #2 is wrong, this is from depparser_macros.h:
	inline int encodeLinkDistance(const int &head_index, const int &dep_index) {
	static int diff;
	diff = head_index - dep_index;
	assert(diff != 0);
	if (diff<0)
	diff=-diff;
	if (diff>10) diff = 6;
	else if (diff>5) diff = 5;
	return diff;
	}

	+ He also has:
	// The size of a sentence and the words
	const unsigned MAX_SENTENCE_SIZE = 256 ;
	const unsigned MAX_SENTENCE_SIZE_BITS = 8 ;

	* TODO:
	+ Add 256 check to the code.
	+ Implement distance.
	+ Find max number of deps.
	+ Implement heads.
	- Seriously test new feature code.
	+ Rerun some old experiments with larger epoch or lower dropout.
	+ Implement arceager.
	= Run acl11 experiments.
	= Run conll07 experiments (arceager).
	+ Make latestop default for beamparser.
	- train.jl: allow length(v)==2*length(net) for param spec each w,b

	+ 03271009-gptacl13.out: Testing new features and running variance experiment:
	$$480131 0.50531 gptacl13   dyuret       r     03/26/2015 19:34:40 ilac.q@ilac-2-0.local
	233	0.985691	0.8772736 (compare to .8789)

	+ 03271008-optacl13.out:
	$$480132 0.50531 optacl13   dyuret       r     03/26/2015 19:34:55 ilac.q@ilac-2-1.local
	234	0.9848177	0.86887866 (compare to .8675)

2015-03-25  Deniz Yuret  <dyuret@ku.edu.tr>

	* Summary: CONLL07 ARCHYBRID EXPERIMENTS: comparing best test
	result (should be test at best validation and should take
	averages) to GN13 archybrid result.  score1 is the old result with
	our fv022b feature set.  score2 is the new result with the
	tacl13hybrid feature set from the paper where words are replaced
	with word vectors and postags are replaced with context vectors.
	Note that this time the training is labeled but the tacl13hybrid
	features do not use the labels.

	parser	score1	score2	GN13
	oparser	.8699	.8675	.8643	03242000-optacl13.out (died at 78, best at 66)
	gparser	.8793	.8789	.8762	03250401-gptacl13.out (died at 213, best at 169)
	beam10	.8865	x	x

	Things tried:
	+ .8789 tacl13hybrid features
	+ .8789 both word+pos features
	+ .8727 unlabeled training
	+ .8709	just word features
	+ .8659 no dropout
	+ .7877 just postag features

	It seems like context vectors are a sufficient substitute for
	postags, they are also necessary, labeled training helps, and
	dropout helps a lot.

	* Experiments: conll07 archybrid experiments.  Most have not
	converged.  We need longer experiments.

	+ 03260132-gptacl13w.out: use only word vecs:
	$$480092 0.50531 gptacl13w  dyuret       r     03/25/2015 13:35:10 ilac.q@ilac-2-1.local
	256	0.9738699	0.87087744

	+ 03270146-gptacl13p.out: use only context vecs:
	$$480093 0.50531 gptacl13p  dyuret       r     03/25/2015 13:35:10 ilac.q@ilac-2-0.local
	gptacl13p.out: crashed twice!?
	187	0.8904479	0.78772736

	+ 03270848-gptacl13wp.out: use both everywhere:
	$$480094 0.50531 gptacl13wp dyuret       r     03/25/2015 13:35:40 ilac.q@ilac-3-0.local
	241	0.98982024	0.8788727

	+ 03261450-gptacl13nd.out: try no dropout:
	$$480095 0.00000 gptacl13nd dyuret       qw    03/25/2015 13:38:48
	26	0.9874197	0.8658805

	+ 03260538-gptacl13nl.out: try unlabeled training:
	$$480097 0.50531 gptacl13nl dyuret       qw    03/25/2015 13:46:17
	228	0.98530364	0.8726764

	+ try multiple runs to see variance

	+ extend training to 2x best
	+ use dev set or fixed epochs

	* acl11hybrid: dictionary.

		paper		GN13		acl11		label
		:----		:---		:----		:----
	single	S0wp		s0wp		STwt		StackWordTag 
		S0w		s0w		STw		StackWord    
		S0p		s0p		STt		StackTag     
		N0wp		n0wp		N0wt		NextWordTag  
		N0w		n0w		N0w		NextWord     
		N0p		n0p		N0t		NextTag	     
		N1wp		n1wp		N1wt		Next+1WordTag
		N1w		n1w		N1w		Next+1Word   
		N1p		n1p		N1t		Next+1Tag    
		N2wp		n2wp		N2wt		Next+2WordTag
		N2w		n2w		N2w		Next+2Word   
		N2p		n2p		N2t		Next+2Tag    
	???					HTw		HeadStackWord	
						HTt		HeadStackTag	
						HTwt		HeadStackWordTag
	pair	S0wpN0wp	s0wp,n0wp	STwtN0wt	StackWordTagNextWordTag	
		S0wpN0w		s0wp,n0w	STwtN0w		StackWordTagNextWord	
		S0wN0wp		s0w,n0wp	STwN0wt		StackWordNextWordTag	
		S0wpN0p		s0wp,n0p	STwtN0t		StackWordTagNextTag	
		S0pN0wp		s0p,n0wp	STtN0wt		StackTagNextWordTag	
		S0wN0w		s0w,n0w		STwN0w		StackWordNextWord	
		S0pN0p		s0p,n0p		STtN0t		StackTagNextTag		
		N0pN1p		n0p,n1p		N0tN1t		NextTagNext+1Tag	
	three	N0pN1pN2p	n0p,n1p,n2p	N0tN1tN2t	NextTagTrigram		
		S0pN0pN1p	s0p,n0p,n1p	STtN0tN1t	StackTagNextTagNext+1Tag
		S0hpS0pN0p	s0hp,s0p,n0p	STHtSttN0t	StackHeadTagStackTagNextTag
		S0pS0lpN0p	s0p,s0lp,n0p	STtSTLDtN0t	StackTagStackLDTagNextTag
		S0pS0rpN0p	s0p,s0rp,n0p	STtSTRDtN0t	StackTagStackRDTagNextTag
		S0pN0pN0lp	s0p,n0p,n0lp	STtN0tN0LDt	StackTagNextTagNextLDTag
	???					HTtHT2tN0t	HeadStackTagHeadStack2TagNextTag
	dist	S0wd		s0wd		STwd		StackWordDist	     
		S0pd		s0pd		STtd		StackTagDist	     
		N0wd		n0wd		N0wd		NextWordDist	     
		N0pd		n0pd		N0td		NextTagDist	     
		S0wN0wd		s0w,n0w,d	STwN0wd		StackWordNextWordDist
		S0pN0pd		s0p,n0p,d	STtN0td		StackTagNextTagDist  
	valency	S0wvr		s0wvr		STwra		StackWordRightArity
		S0pvr		s0pvr		STtra		StackTagRightArity 
		S0wvl		s0wvl		STwla		StackWordLeftArity 
		S0pvl		s0pvl		STtla		StackTagLeftArity  
		N0wvl		n0wvl		N0wla		NextWordRightArity ?? NextWordLeftArity
		N0pvl		n0pvl		N0tla		NextTagRightArity  ?? NextTagLeftArity
	unigram	S0hw		s0hw		STHw		StackHeadWord
		S0hp		s0hp		STHt		StackHeadTag 
		S0L		s0L		STi		StackLabel   
		S0lw		s0lw		STLDw		StackLDWord 
		S0lp		s0lp		STLDt		StackLDTag  
		S0lL		s0lL		STLDi		StackLDLabel
		S0rw		s0rw		STRDw		StackRDWord 
		S0rp		s0rp		STRDt		StackRDTag  
		S0rL		s0rL		STRDi		StackRDLabel
		N0lw		n0lw		N0LDw		NextLDWord  
		N0lp		n0lp		N0LDt		NextLDTag   
		N0lL		n0lL		N0LDi		NextLDLabel 
	third	S0h2w		s0h2w		STHHw		StackHeadHeadWord
		S0h2p		s0h2p		STHHt		StackHeadHeadTag 
		S0hL		s0hL		STHi		StackLabel ?? StackHeadLabel	 
		S0l2w		s0l2w		STL2Dw		StackL2DWord	 
		S0l2p		s0l2p		STL2Dt		StackL2DTag	 
		S0l2L		s0l2L		STL2Di		StackL2DLabel	 
		S0r2w		s0r2w		STR2Dw		StackR2DWord	 
		S0r2p		s0r2p		STR2Dt		StackR2DTag	 
		S0r2L		s0r2L		STR2Di		StackR2DLabel	 
		N0l2w		n0l2w		N0L2Dw		NextL2DWord	 
		N0l2p		n0l2p		N0L2Dt		NextL2DTag	 
		N0l2L		n0l2L		N0L2Di		NextL2DLabel     
		S0pS0lpS0l2p	s0p,s0lp,s0l2p	STtSTLDtSTL2Dt	StackTagStackLDTagStackL2DTag
		S0pS0rpS0r2p	s0p,s0rp,s0r2p	STtSTRDtSTR2Dt	StackTagStackRDTagStackR2DTag
		S0pS0hpS0h2p	s0p,s0hp,s0h2p	STHHtSTHtSTt	StackHeadHeadTagStackHeadTagStackTag
		N0pN0lpN0l2p	n0p,n0lp,n0l2p	N0tN0LDtN0L2Dt	StackTagNextTagNextLDTagNextTagNextL2DTag ?? NextTagNextLDTagNextTagNextL2DTag
	labset	S0wsr		s0wsr		STwrp		StackWordRightSetoftags
		S0psr		s0psr		STtrp		StackTagRightSetoftags 
		S0wsl		s0wsl		STwlp		StackWordLeftSetoftags 
		S0psl		s0psl		STtlp		StackTagLeftSetoftags  
		N0wsl		n0wsl		N0wlp		Next0WordLeftSetoftags ?? NextWordLeftSetoftags  
		N0psl		n0psl		N0tlp		Next0TagLeftSetoftags  ?? NextTagLeftSetoftags  
	lcf					STl		StackLemma 
						STc		StackCPOS  
						STf		StackFeats 
						N0l		NextLemma  
						N0c		NextCPOS   
						N0f		NextFeats  
						N1l		Next+1Lemma
						N1c		Next+1CPOS 
						N1f		Next+1Feats

2015-03-24  Deniz Yuret  <dyuret@ku.edu.tr>

	* GN13: experiments with matching features: gptacl13 and optacl13.
	+corpus: conll07 (deprel=19+ROOT)
	+parser: archybrid (note that archybrid13 is slightly different)
	?feats: tacl13hybrid (replaced form with word vector, postag with context vector)
	=this is a pretty crappy feature set, should also try adding word vectors for all tokens
	+training: 256 epochs static/dynamic oracle training.
	+embedding: wikipedia2MUNK-100
	+eval: including punctuation

	* gptacl13: 3m32s/epoch
	$$480081 0.50531 gptacl13   dyuret       r     03/24/2015 15:21:25 ilac.q@ilac-0-3.local
	* optacl13: 3m33s/epoch
	$$480080 0.50531 optacl13   dyuret       r     03/24/2015 15:20:10 ilac.q@ilac-2-1.local

	* TODO:
	+ add acl11eager to flist.
	- add acl11 adapted to hybrid?
	-- use archybrid with acl11 features with labels
	-- Design better featureset for archybrid.
	+ update features to have labels, labelsets, new encoding for valence and distance
	+ s0hp, s0hw, (we don't have heads)
	+ d (s0n0, 10+ encoded, we have 4+ encoding with (-1 0 3), 8bit encodings with +-7)
	+ s0vl, s0vr (child count flat encoding, we have 3+ encoding)
	+ s0L (deprel)
	+ s0h2{w,p} grandparent
	+ s0sr, s0sl right/left label set
	+ compare acl11 with goldberg implementation: encoding etc.
	  depparser.cpp, depparser_weight.h, state.h
	  under: src/common/depparser/implementations/arceager
	+ rewrite bparser with deprels.
	+ implement arceager, make the code parser generic.
	+ create better language for specifying flists.
	+ Make xy in pxy optional in parsers.

2015-03-22  Deniz Yuret  <dyuret@ku.edu.tr>

	* DEPRELS: Unfortunately they change a lot.
	acl11: NMOD, VMOD, P, PMOD, SUB, ROOT, OBJ, AMOD, VC, SBAR, PRD, DEP (from: acl11/src/english/dependency/label/penn.h)
	conll07: NMOD, P, PMOD, SBJ, ADV, OBJ, COORD, VMOD, ROOT, AMOD, VC, IOBJ, CC, PRT, PRN, LGS, DEP, GAP, EXP, TMP
	conllWSJToken_wikipedia2MUNK-100: NMOD, P, PMOD, SBJ, OBJ, ROOT, ADV, VC, COORD, NAME, DEP, TMP, CONJ, LOC, AMOD, APPO, PRD, IM, SUB, OPRD, SUFFIX, TITLE, DIR, MNR, POSTHON, PRP, PRT, LGS, EXT, PRN, LOC-PRD, EXTR, DTV, PUT, GAP-SBJ, GAP-OBJ, DEP-GAP, GAP-TMP, GAP-PRD, PRD-TMP, PRD-PRP, BNF, GAP-LGS, GAP-LOC, DIR-GAP, LOC-OPRD, VOC, GAP-PMOD, ADV-GAP, GAP-VC, EXT-GAP, GAP-NMOD, AMOD-GAP, DTV-GAP, GAP-LOC-PRD, GAP-MNR, DIR-PRD, GAP-PRP, EXTR-GAP, MNR-PRD, LOC-TMP, GAP-OPRD, LOC-MNR, GAP-SUB, GAP-PUT, MNR-TMP, DIR-OPRD

	So we have conll2dict.jl which takes a conll corpus and construct
	dictionaries for forms, postags, and deprels.  Then we have
	conll2jld.jl which takes this dictionary and saves the conll
	corpus in a jld file replacing strings with ints (based on their
	position in dict).  Note: deprel ROOT is special, it does not
	create a new left/right move and is represented by the special
	value 0.

	* Summary:

	+ conll07 experiments: comparing best test result (should be test
	at best validation and should take averages) to GN13 archybrid
	result (we are not using deprels).

	parser	score	GN13
	oparser	.8699	.8643	03210931-opconll07.out
	gparser	.8793	.8762	03210908-gpconll07.out
	beam10	.8865	___	03221208-bpconll07.out

	+ acl11 experiments: ZN11 for comparison has word accuracy
	dev=.9314 test=.9290.  Word accuracy (excluding punct) is about 1%
	higher than head accuracy (including punct).  We are not using
	deprels.  We are using nbeam=10, they use 64.  We are using
	archybrid, they use arceager.  test1 is the test score at best dev
	result.  test2 is the best test score.

	parser	dev	test1	test2
	oparser	.9093	.9046	.9060	03212217-opacl11.out
	gparser	.9136	.9096	.9109	03212217-gpacl11.out
	beam10	.9158	.9122	.9145	03240436-bpacl11.out

	+ conllWSJToken_wikipedia2MUNK-100 experiments: Different gold
	head than acl11.  Latestop better than earlystop.
	x How about train on all mincost state/move pairs (if multiple):
	loses the ability to get precise move count.
	+ beam64 too slow, get pepochs to work.

	parser	dev	test1	test2
	beam10a	.9186	.9132	.9136	03201925-julia3_btrain_jl.out: using whole beam to train, quit at epoch=77
	beam64	.9212	.9151	.9165	bparse64.out -- stopped at epoch=166
	beam10l	.9211	.9169	.9171	03220927-bparselatestop.out: no earlystop, crashed at epoch=207
	beam10	.9205	.9150	.9166	03220548-bparsedbg.out: earlystop

	+ gfeatures experiments: Large feature sets more effective with
	nnets compared to perceptron.  Redo feature optimization and/or
	take a careful look at ZN11 and GN13 feature sets.

2015-03-21  Deniz Yuret  <dyuret@ku.edu.tr>

	* Summary:
	+ Everybody is using deprels even when training for unlabelled
	accuracy.
	+ ZN11 uses different heads than Husnu&Volkan's dataset.  I have
	created acl11 files to match ZN11.
	+ Nnets seem to handle extra features better than perceptrons,
	high dimensional feature sets seem to do well.
	+ We are better than GN13 even without deprels, however this is
	directly optimizing on test data, we need to use dev.
	+ We have the code for ZN11 and GN13, we can take a look at the
	feature sets in detail.
	+ Suzuki uses 3.5B words for semisupervised learning, we should
	grow our LM and SCODE corpora as well.
	+ ZN11 uses arceager, GN13 best result with arceasy.

	* ZN11: (Zhang&Nivre11) nbeam=64 dev=.9314 tst=.9290
	wordacc (excluding punct) conv=Penn2Malt.  parser=arceager.
	learner=perceptron.  uses labels to improve link accuracy!  (seems
	they get .65) also check out their feature set, and their distance
	encoding.  Their whole dataset is projective!

	* GN13: (Goldberg&Nivre13) .8643/.8762 static/dynamic archybrid on
	conll07 headacc (including punct).  no beam.  I think uses labels,
	but better check feature specs.

	* TODO: parser and training
	+ ** add deprel labels as features! **: features.jl, archybrid.jl
	- output two variables (move+label) or one (movelabel)?
	+ check features and encodings of zhang&nivre11.
	- use oparser for fselect.  faster if only test at the end.
	- need fselect again for labeled parser.
	- try previous moves as features? (rnn idea)
	- try arceasy (better on Goldberg&Nivre13) 
	+ Try arceager (Zhang&Nivre11).
	+ train.jl: write pepochs option to get nbeam=64 to work.
	- train.jl: implement earlystop for efficiency (Zhang does it)
	-- latestop seems to perform better?
	+ train.jl: longer training (stop if 2x best epoch)
	+ train.jl: save models
	+ train.jl: compute eval.py (wordacc) score.
	= can we use rnn's to learn parser-action sequences? prepare
	  ordered data for ozan.
	= better vectors: fastsubs and scode on bigger better data.  which
	  data did volkan use? onur interested. sent email.
	+ are they (Goldberg,Zhang) using the deprels during parsing?
	  (BILOU is better than BIO) YES!
	+ which arc system are they (Zhang&Nivre11) using? arceager.

	* TODO: model and optimization
	- play with optimization, rmsprop, adam, layers, dropout, hidden layers?
	- alternative to adagrad?
	- try more hidden layers.

	* TODO: features
	= fv1768: memory error
	x try bparse 10 epochs all Flist: oparse instead for fselect.
	- try local search around best feats
	- feature select with acl11
	- feature select with conll07
	+ features from ZN11 and GN13

2015-03-20  Deniz Yuret  <dyuret@ku.edu.tr>

	* ~/src/acl11: Got Yue Zhang's acl11 data.  Heads are different!
	+ ** generate new dataset with acl11 heads. **
	+ generate new dataset with conll07.

	Note: fv021a may not be ideal for acl11! run gfeatures after fixing bugs.
	Note: using fv022b for conll07.

	* 03210931-opconll07.out:
	$$480064 0.50531 opconll07  dyuret       r     03/20/2015 18:39:10 ilac.q@ilac-0-0.local
	1	0.8383803	0.8205077
	2	0.8559474	0.841695
	4	0.87357944	0.8420947
	8	0.8902576	0.84929043
	16	0.91164714	0.8560864
	32	0.9369286	0.85808516
	64	0.9609493	0.86128324
	128	0.97914565	0.86128324
	170	0.98390406	0.86987805	*** (compare to GN13=.8643)
	256	0.9885506	0.86508095

	* 03210908-gpconll07.out:
	$$480065 0.50531 gpconll07  dyuret       r     03/20/2015 18:45:10 ilac.q@ilac-3-0.local
	1	0.8376861	0.8237058
	2	0.79815173	0.77953225
	4	0.87328166	0.85108936
	8	0.89544153	0.8604837
	16	0.91665864	0.86667997
	32	0.9414877	0.8712772
	64	0.964232	0.8702778
	128	0.9813267	0.8786728
	133	0.98199844	0.87927246	*** (compare to GN13=.8762)
	256	0.98990756	0.8724765

	* 03221208-bpconll07.out:
	$$480066 0.50531 bpconll07  dyuret       r     03/20/2015 18:45:55 ilac.q@ilac-2-1.local
	$ grep DATA bpconll07.out | awk '$2>=a{print;a=$2*2}'
	1	0.8489049	0.836698
	2	0.86899793	0.8554867
	4	0.8904457	0.8686788
	8	0.9080262	0.875075
	16	0.92726606	0.88227063
	32	0.94914156	0.88127124
	54	0.9653002	0.8864681	***
	64	0.9700833	0.8772736
	128	0.9850327	0.875075
	256	0.9918983	0.8680791

	* 03200918-gfeatures_sh.out: experiment with features (honnibal
	comment).  This is on husnu deps.
	+ try gparse 10 epochs all Flist
	$$479993 0.50531 _gfeatures dyuret       r     03/19/2015 10:46:40 ilac.q@ilac-2-3.local
	$$479998 0.50531 _gfeatures dyuret       r     03/19/2015 11:46:40 ilac.q@ilac-1-3.local
	= try to debug and fix the crashes
	$$480067 0.50531 gfeatures2 dyuret       qw    03/20/2015 19:19:08
	$$480068 0.50531 gfeatures3 dyuret       qw    03/20/2015 21:53:02
	$$480069 0.50531 gfeatures3 dyuret       r     03/22/2015 13:12:40 ilac.q@ilac-2-2.local
	$ egrep '^(DATA:.10|julia3)' _gfeatures_sh.out
	fv1768	0.92688215	0.9029838	0.8982076	(3348 dims, 865MiB)
	fv031a	0.9175582	0.90168756	0.8972373	(2512 dims)
	fv034	0.92510116	0.9013386	0.8971491	(2452 dims, 660MiB)
	fv021a	0.9179561	0.90113914	0.89709616	(1326 dims)
	fv084	0.92291176	0.9010644	0.8951027	(3138 dims)
	fv022a	0.918115	0.9009896	0.8971138	(1426 dims)
	fv023	0.9185719	0.9005908	0.8966375	(1526 dims)
	fv022	0.9171161	0.9003415	0.8965669	(1516 dims)
	fv102	0.9187382	0.90001744	0.8975549	(4638 dims)
	fv022b	0.916714	0.8999177	0.89713144	(1424 dims)
	fv023a	0.91787714	0.8998679	0.89737844	(1616 dims)
	fv018	0.91692454	0.8995937	0.8934091	(1608 dims)
	fv804	0.91603404	0.89899546	0.89492625	(1604 dims)
	fv021	0.91659826	0.89894557	0.8955437	(1416 dims)
	fv708	0.9135615	0.89847195	0.89399123	(1408 dims)
	fv019	0.915633	0.8984221	0.89533204	(1411 dims)
	fv015a	0.914752	0.8978488	0.8922976	(1401 dims)
	fv018a	0.9154783	0.89777404	0.89423823	(1407 dims)
	fv017	0.9170309	0.8975247	0.89513797	(1508 dims)
	fv039	0.9245001	0.897450	0.89577305	(2744 dims, 727MiB)
	fv130	0.91527617	0.8966772	0.89319736	(3538 dims, 909MiB)
	fv808	0.91797924	0.89655256	0.89259756	(1608 dims)
	fv017a	0.916613	0.89615375	0.893021	(1508 dims)
	fv136	0.9144846	0.8956053	0.8926505	(3544 dims, 910MiB)
	fv012	0.9068354	0.88982224	0.88806367	(1200 dims)
	fv008	0.9009608	0.8860832	0.88349444	(800 dims)
	fv008w	0.8957652	0.8806242	0.8796309	(800 dims)


2015-03-19  Deniz Yuret  <dyuret@ku.edu.tr>

	* 03201925-julia3_btrain_jl.out: Train using beam parser. ~1h per
	epoch.  Training on the whole beam with nbeam=10.
	+ merge mincostpath with master after this one finishes.
	$$479844 0.50531 julia3_btr dyuret       r     03/17/2015 12:01:55 ilac.q@ilac-0-3.local
	1	0.8714639358032035	0.8880773736819803	0.8838649354315151
	2	0.8950433643212408	0.8938604581598824	0.890762825488674
	4	0.9122091687400475	0.903033626642072	0.8975901488956319
	8	0.9273346259121167	0.9078694817658349	0.9040117140639334
	16	0.9424559294340376	0.912007378418127	0.9076811798743913
	32	0.9569711670068192	0.9151481915397462	0.9107331874955896
	64	0.9691327587380277	0.9175910461898945	0.9127443370263214
	74	0.9711445121199407	0.9180397337786973	0.9135734951661845	*t*
	77	0.9718000903088589	0.9186130568088342	0.9132030202526286	*d*

	* 03290018-bparse64.out: experiment with larger beams 1h22m/epoch
	$$479988 0.50531 bparse64   dyuret       r     03/19/2015 09:48:25 ilac.q@ilac-1-0.local
	1	0.88225925	0.8752399	0.87107474
	2	0.8944715	0.8857093	0.8815892
	4	0.9085364	0.8967271	0.8914861
	8	0.9206171	0.90582544	0.9008715
	16	0.93292725	0.9116833	0.9058465
	32	0.9474447	0.9167186	0.91170347
	64	0.96225166	0.91851336	0.9141204
	113	0.97382075	0.92115563	0.9150907	*d*
	128	0.9761996	0.9197597	0.9152671
	156	0.9793417	0.91841364	0.9164667	*t*
	166	0.98041004	0.9195603	0.91507304	stopped

	* 03220927-bparselatestop.out: why is this different from static
	oracle training?  we are rewarding mincost state/move pairs on the
	beam.  are the mincost states on the beam that different than the
	mincost states for the static oracle?  why not use earlystop in
	gparser?  **why not follow the whole mincostpath and not use
	earlystop in bparser?**

	$$480009 0.50531 bparselate dyuret       r     03/19/2015 14:17:25 ilac.q@ilac-2-2.local
	$$480024 0.50531 bparselate dyuret       r     03/19/2015 17:07:40 ilac.q@ilac-2-2.local
	1	0.8824845	0.8760874	0.8711453
	2	0.8931568	0.8864322	0.8810599
	4	0.9077248	0.8963033	0.89115095
	8	0.92096025	0.9067976	0.8996013
	16	0.9335746	0.9120572	0.90686965
	32	0.94735837	0.9163447	0.91173875
	64	0.9624811	0.9194606	0.9139969
	121	0.9752039	0.9198843	0.9171371	*t*
	128	0.9760491	0.92015857	0.91664314
	129	0.97622174	0.9211307	0.9169078	*d*
	207	0.9833121	0.9198843	0.91528475	crashed

	* 03220548-bparsedbg.out: mincostpath bparser results: at most one
	xy pair per beam (the first one which has the initial mincost) is
	added to the training set. nbeam=10.  (18m50s per epoch) Note: trn
	improvement is slower compared to whole beam training.  dev/tst
	catches up and passes after 32 epochs.  Less overfitting?  Speed
	3x faster.

	$$479933 0.50531 bparsedbg  dyuret       r     03/18/2015 21:32:10 ilac.q@ilac-0-1.local
	1	0.8811414	0.8743675	0.87079245
	2	0.8940389	0.8873545	0.8804777
	4	0.9079269	0.89695144	0.8927387
	8	0.92069286	0.9061495	0.89916027
	16	0.9332304	0.9117581	0.9058112
	32	0.94746995	0.91639453	0.91230327
	64	0.9625506	0.9181644	0.9151789
	128	0.97627544	0.91808957	0.91576105
	130	0.97652704	0.9197597	0.9165726	*t*
	193	0.982411	0.92053246	0.91503775	*d*
	256	0.985992	0.9191365	0.91507304

	* 03240436-bpacl11.out: Trying acl11 dependencies.
	$$480062 0.50531 bpacl11    dyuret       r     03/20/2015 18:27:55 ilac.q@ilac-2-3.local
	1	0.87517524	0.86920756	0.86677015
	2	0.88630337	0.8795274	0.87807846
	4	0.9019197	0.891617	0.8888046
	8	0.9159751	0.8992198	0.8985252
	16	0.92985153	0.9061495	0.9052113
	32	0.94513106	0.91220677	0.9099746
	64	0.9617148	0.9144004	0.9116329
	79	0.9671715	0.9158212	0.9121622	*d* (ZN11:9314w)
	121	0.9770028	0.91380215	0.9145438	*t* (ZN11:9290w)
	128	0.97827536	0.91502357	0.91406745
	256	0.99009085	0.9123564	0.9130795

	* TODO:
	+ headpct-wordpct diff around 1% according to vectorparser/ChangeLog.
	= compare Penn2Malt conversion with Zhang: emailed Zhang.
	+ check Suzuki11.
	+ merge mincostpath and structure code to experiment with other variants.
	= parse conll07 for static/dynamic comparison.
	= experiment with subsets of the beam to use for training (zhang email)?

	* Chen&Zhang&Zhang14: .9422 is best from related work Suzuki11 in
	http://www.aclweb.org/anthology/C14-1078. Conversion with
	Penn2Malt.  Uses Carreras07 decoder with MIRA and Bohnet2010 features.

	* Suzuki11: (condensed feature representations, semisupervised)
	cites dev/tst Suzuki11:9433/9422, Koo08:9330/9316, Chen09:?/9316,
	Suzuki09:9413/9379.  Uses 3.7b token for unsupervised learning (as
	Suzuki09).  Suzuki 09 uses conv=yamada parser=2nd-order.

	* Koo08: tst23=.9316 (excluding punct).  Uses Carreras07 (second
	order).  Cluster info adds +1.14.


2015-03-18  Deniz Yuret  <dyuret@ku.edu.tr>

	* todo:
	= write bparser:mincostpath - testing on *julia*
	= add options to gtrain/btrain - testing on {ogb}parsedbg.out
	+ try onur's problem
	x try bparser without dropout: no reason to do it with mincostpath, input similar to oparser.
	= try gparser with other fvectors

2015-03-16  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	+ solve memory problems: x=10GB, bparse=100GB!
	+ save networks: implement savenet, testnet or copy:save copy:test
	= beam earlystop? only train with mincostpath?  same with greedy?
	= play with features

	* memory:
	x do we need to wait for @everywhere gc()?
	x whos() does not work from inside meminfo: turn into macro?: still does not show locals
	= check out getBytes from http://stackoverflow.com/questions/28402989/check-size-in-bytes-of-variable-using-julia
	x if restarting workers does not help, just write code without DArrays.
	x maybe forget about workers and write multithreaded.
	+ but DArrays are only used for corpora, not the returned x!?  help debug gc().

2015-03-15  Deniz Yuret  <dyuret@ku.edu.tr>

	* upper-bound: These are head accuracies with oracle parser (less than 100% because of nonplanar trees?)
	evalheads(p1,trn) => 0.9940970160879469
	evalheads(p2,dev) => 0.9950395094349029
	evalheads(p3,tst) => 0.9935960764942489

	* 03160543-julia3_otrain_jl.out: Train using static oracle. 4m07s
	per epoch. (5m50s with testing)

	epoch	trn			dev			tst
	1	0.8739110847259238	0.8660916818306453	0.8615129489803119
	2	0.8855433734584665	0.8766607672557769	0.8707218968315574
	4	0.8988882432938818	0.8874541964753098	0.8828064356784984
	8	0.9100005473522885	0.8930877184236109	0.8891574341965987
	16	0.9229485867784949	0.9015130742577959	0.8943264413238303
	32	0.9391302151094494	0.9064486377346263	0.9001481899654223
	64	0.9567865368178622	0.9097639404741132	0.903288405899372
	128	0.9730323737826675	0.9098636488271805	0.9051054971420507
	256	0.9837520578340849	0.9088665652965077	0.9075047632488886

	* 03200328-oparsedbg.out: Replicating otrain results with new train.jl (6m22s/epoch)
	$$479920 0.50500 oparsedbg  dyuret       r     03/18/2015 19:55:10 ilac.q@ilac-0-2.local
	1	0.8737332	0.86576766	0.8628537
	2	0.8857002	0.87501556	0.8715687
	4	0.89788723	0.88446295	0.8803366
	8	0.91024685	0.8940349	0.88966906
	16	0.9238307	0.901538	0.89517325
	32	0.93902916	0.9065733	0.8999365
	64	0.95688546	0.90904105	0.9024416
	128	0.97318393	0.91016275	0.9060052
	254	0.98392576	0.9116335	0.9063228	*d*
	255	0.9839089	0.91013783	0.90736365	*t*
	256	0.98388153	0.910786	0.90690494

	* 03212217-opacl11.out: Trying the ACL11 Zhang dependencies.
	$$480059 0.50531 opacl11    dyuret       r     03/20/2015 18:15:10 ilac.q@ilac-2-0.local
	1	0.86862916	0.8634993	0.86227155
	2	0.88202244	0.87424284	0.87324464
	4	0.8953294	0.8846873	0.8833357
	8	0.90825427	0.8924396	0.8921036
	16	0.92300224	0.89936936	0.8979077
	32	0.9404091	0.9041554	0.9030238
	64	0.95960015	0.90749556	0.9038882
	128	0.9779785	0.908044	0.90415287
	205	0.9867804	0.9072712	0.90602285	*t*
	210	0.9871225	0.9092903	0.9046115	*d*
	256	0.9896782	0.9065234	0.9043998

	* 03171146-julia3_gtrain_jl.out: Train using greedy parser. 6m30s per epoch.
	1	0.8740110817786423	0.8695565470997333	0.8623244654576248
	2	0.8796424947475232	0.8704539222773388	0.8683755557123704
	4	0.8938568126413117	0.8808235909963357	0.8785018700162304
	8	0.9140688484970969	0.8979734277239075	0.8951732411262437
	16	0.9277031834851184	0.9051773562330184	0.9003246065909252
	32	0.941745927488453	0.9094149612383777	0.9050349304918496
	64	0.9574433595641392	0.9112595657701223	0.9091101545409639
	93	0.9657357467358857	0.9154223895106812	0.9110330957589443
	127	0.9721671361265142	0.9149986290101453	0.9128678286641733

	* 03192351-gparsedbg.out: Replicating gtrain results (6m32s/epoch) with new train.jl
	$$479926 0.50531 gparsedbg  dyuret       r     03/18/2015 19:58:55 ilac.q@ilac-0-0.local
	1	0.87359005	0.86753744	0.8616188
	2	0.88026565	0.87152576	0.86717594
	4	0.89791775	0.8860832	0.88430595
	8	0.9142257	0.90056586	0.8936737
	16	0.92736214	0.90445447	0.8997248
	32	0.9417891	0.90948975	0.9047703
	64	0.95761913	0.91292965	0.9092689
	128	0.9720545	0.91372734	0.91122717
	194	0.9796385	0.9158212	0.9123562	*d*
	238	0.98255104	0.9152479	0.9139616	*t*
	256	0.98354787	0.9134033	0.91325593

	* 03212217-gpacl11.out: Trying the acl11 dependencies.
	$$480058 0.50531 gpacl11    dyuret       r     03/20/2015 18:14:25 ilac.q@ilac-1-3.local
	1	0.8675871	0.8654436	0.86175996
	2	0.85359275	0.8475958	0.8446828
	4	0.8899264	0.87940276	0.87911934
	8	0.91075844	0.89585465	0.8929857
	16	0.92462856	0.901887	0.89970714
	32	0.94124806	0.90712166	0.90517604
	64	0.9581886	0.9111848	0.90812224
	116	0.9726871	0.9120572	0.9109096	*t*
	128	0.9751281	0.9124561	0.90872204
	184	0.98290575	0.9135778	0.90960413	*d*
	256	0.98849404	0.9113094	0.9093748

2015-03-14  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/oparser.jl: Oracle parser: useful for generating static oracle training data.
	julia> @time o2=KUparser.oparse(dev,feats,20);
	elapsed time: 2.306022569 seconds (430 MB allocated, 44.86% gc time in 6 pauses with 3 full sweep)
	julia> mean(vcat(o1[1]...) .== vcat(map(x->x.head,dev)...))
	0.9950395094349029

	* src/gparser.jl:
	x do not need to allocate p, y, etc. for the whole corpus in batch version.

	* TODO:
	+ return xy from gparser and bparser.
	+ train. (need logploss, need earlystop?, try rmsprop?, adam?: adagrad may not do well on changing data)
	+ static oracle
	+ greedy parser
	+ beam parser: still has memory issues
	= feature select.

	* INFO:
	+ biyofiz gpu memory is sufficient for nbeam*nbatch*ncpu <= 10000

	julia> @time b42y=KUparser.bparse(dev,net,feats,100,5,20);
	elapsed time: 261.986853539 seconds (3 MB allocated)
	julia> @time b41y=KUparser.bparse(dev,net,feats,10,50,20);
	elapsed time: 32.315438529 seconds (3 MB allocated)
	julia> find(b41y .!= b42y)
	1-element Array{Int64,1}:
	1324

	+ beam parser gives better head score with same model:

	julia> gold=map(x->x.head, dev);
	julia> mean(vcat(gold...) .== vcat(g0...))
	0.9105865343869183
	julia> mean(vcat(gold...) .== vcat(b41y...))
	0.9154473165989481

	* TODO: src/bparser.jl: minibatch version:
        x do not keep computing costs for finished sentences: too minor
        x do all beam elements finish simultaneously?
        x cache cost in parser?
	x repeated states on the beam?
	= nbeam=10 and nbeam=100 give the same parse?
	== in all except sent 1324. beam1 vs beam10 differ in 224 sentences.

	* test/timing.jl: minibatch version speed test:

	# Greedy parser
	g0=KUparser.gparse(dev,gnet,feats)		elapsed time: 148.237107122 seconds
	g1=KUparser.gparse(dev,gnet,feats,1700)		elapsed time: 22.188889154 seconds
	g2=KUparser.gparse(dev,gnet,feats,1700,20)	elapsed time: 8.051600384 seconds
	g3=KUparser.gparse(dev,gnet,feats,100)		elapsed time: 26.318353452 seconds
	g4=KUparser.gparse(dev,gnet,feats,100,20)	elapsed time: 8.062792516 seconds

	# These are with beam size 1
	# Final parses same as g0
	b0=KUparser.bparse(dev,gnet,feats,1)		elapsed time: 156.000890758 seconds
	b1=KUparser.bparse(dev,gnet,feats,1,1700)	elapsed time: 30.145607698 seconds
	b2=KUparser.bparse(dev,gnet,feats,1,1700,20)	elapsed time: 8.18903106 seconds
	b3=KUparser.bparse(dev,gnet,feats,1,100)	elapsed time: 31.510566003 seconds
	b4=KUparser.bparse(dev,gnet,feats,1,100,20)	elapsed time: 8.234869093 seconds

	# These are with beam size 10 on the first 100 sentences of dev:
	# Final parses not same with g0[1:100]
	b01=KUparser.bparse(dev[1:100],gnet,feats,10)		elapsed time: 25.057099378 seconds
	b11=KUparser.bparse(dev[1:100],gnet,feats,10,100)	elapsed time: 14.705737159 seconds
	b21=KUparser.bparse(dev[1:100],gnet,feats,10,100,20)	elapsed time: 5.154158539 seconds
	b31=KUparser.bparse(dev[1:100],gnet,feats,10,10)	elapsed time: 16.469459534 seconds
	b41=KUparser.bparse(dev[1:100],gnet,feats,10,10,20)	elapsed time: 5.161457464 seconds

	# These are with beam size 100 on the first 100 sentences of dev:
	# Final parses same as b01
	b02=KUparser.bparse(dev[1:100],gnet,feats,100)		elapsed time: 137.201635533 seconds
	b12=KUparser.bparse(dev[1:100],gnet,feats,100,100)	elapsed time: 132.684041541 seconds
	b22=KUparser.bparse(dev[1:100],gnet,feats,100,100,20)	elapsed time: 18.501004294 seconds
	b32=KUparser.bparse(dev[1:100],gnet,feats,100,10)	elapsed time: 132.337806865 seconds
	b42=KUparser.bparse(dev[1:100],gnet,feats,100,10,20)	elapsed time: 18.514346591 seconds


2015-03-13  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/bparser.jl: speed test:

	# Time for greedy parser on 1700 sentence dev
	julia> @time g=KUparser.gparse(dev,gnet,feats);
	elapsed time: 149.497789522 seconds (4116 MB allocated, 1.06% gc time in 189 pauses with 0 full sweep)

	# Time for beam parser on same data with beam=1
	julia> @time b=KUparser.bparse(dev,gnet,feats,1);
	elapsed time: 159.778490775 seconds (7173 MB allocated, 3.76% gc time in 328 pauses with 9 full sweep)

	# Time on dev[1:100]
	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,1);
	elapsed time: 9.962360704 seconds (440 MB allocated, 5.42% gc time in 20 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,5);
	elapsed time: 16.47657518 seconds (1940 MB allocated, 8.55% gc time in 89 pauses with 2 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,10);
	elapsed time: 27.863031912 seconds (3773 MB allocated, 12.66% gc time in 172 pauses with 6 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,50);
	elapsed time: 84.229235102 seconds (17997 MB allocated, 18.13% gc time in 806 pauses with 25 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,100);
	elapsed time: 158.230640377 seconds (35313 MB allocated, 16.89% gc time in 1549 pauses with 41 full sweep)

	# Time tests with ncpu=20

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,1,20);
	elapsed time: 9.237851461 seconds (2 MB allocated)
	elapsed time: 9.766501577 seconds (107 MB allocated, 4.21% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,5,20);
	elapsed time: 9.447347633 seconds (2 MB allocated)
	elapsed time: 9.975221305 seconds (107 MB allocated, 4.11% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,10,20);
	elapsed time: 13.658449233 seconds (2 MB allocated)
	elapsed time: 14.184126282 seconds (107 MB allocated, 2.89% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,50,20);
	elapsed time: 15.286421047 seconds (2 MB allocated)
	elapsed time: 15.809166647 seconds (107 MB allocated, 2.60% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,100,20);
	elapsed time: 27.447839359 seconds (2 MB allocated)
	elapsed time: 28.380576273 seconds (107 MB allocated, 2.96% gc time in 5 pauses with 2 full sweep)


2015-03-12  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO: src/bparser.jl:
	+ early stop?  could implement by copying into big x
	+ mincost may not be 0 for non-planar sentences
	= sortperm! suggest AbstractArray to julia
	= Now we sort the nc candidates and copy top np back to the beam
	x softperm! may not be necessary when nc <= beam (unless we care about the first candidate being the best)
	= do we need features when we have 0 or 1 valid move?
	= do not return y from gparser, return x,z consistently from each method
	x maybe have optional trn struct and return trn.x trn.y trn.nx
	x check for identical states on the beam: score will be difft

2015-03-08  Deniz Yuret  <dyuret@ku.edu.tr>

	* Speed-test:

	julia@iui> @time KUparser.gparse(trn, net, feats, 2000, 20);
	elapsed time: 40.50693341 seconds (9502 MB allocated, 8.38% gc time in 14 pauses with 11 full sweep)
	elapsed time: 86.205662824 seconds (107430 MB allocated, 6.12% gc time in 86 pauses with 14 full sweep)

	julia@bio> @time KUparser.gparse(trn, net, feats, 500, 20);
	elapsed time: 75.61331844 seconds (9476 MB allocated, 3.19% gc time in 8 pauses with 6 full sweep)
	elapsed time: 112.552530706 seconds (107352 MB allocated, 4.21% gc time in 75 pauses with 9 full sweep)

	julia3@ilac> @time KUparser.gparse(trn, net, feats, 1700, 12);
	elapsed time: 86.231203 seconds (11419169336 bytes allocated, 7.88% gc time)
	elapsed time: 123.933778 seconds (75581738656 bytes allocated, 16.60% gc time)

2015-03-05  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	= write bparser
	= real use of rnn's is to map text to meaning!

	= should we try parallel for?
	= see how SharedArray is implemented and use it for net weights: x is bigger!

	* src/gparser.jl: gpu minibatch version:

	# dev has 1700 sentences and 40117 words
	# fastest matlab test speed was 26 sents/sec = 1.6298 ms/word
	# fastest matlab dump speed was 30 sents/sec = 1.4125 ms/word
	# fastest julia test speed is 80 sents/sec = 0.5286 ms/word
	# fastest julia dump speed is 116 sents/sec = 0.3652 ms/word

	# 3.6986 ms/word: parsing sentences one at a time
	include("fooparser.jl")
	julia> @time h2=KUparser.gparse(dev, n, Feats.fv021a);
	elapsed time: 148.37933571 seconds (4145 MB allocated, 0.83% gc time in 190 pauses with 0 full sweep)

	# 0.5286 ms/word: parsing sentences in minibatches
	julia> @time h1=KUparser.gparse(dev, n, Feats.fv021a, 1700);
	elapsed time: 21.206189373 seconds (6355 MB allocated, 8.16% gc time in 273 pauses with 1 full sweep)

	# 0.3652 ms/word: everything except KUnet prediction
	julia> @time h0=KUparser.gparse(dev, n, Feats.fv021a, false);
	elapsed time: 14.648858577 seconds (3488 MB allocated, 5.64% gc time in 160 pauses with 0 full sweep)

	# For training with Julia I expect 8 mins to parse, 2 mins to
	update, 10 mins per epoch.

2015-03-04  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/features.jl:
	> @time foo=KUparser.gparse(dev[1:100], n, Feats.fv021a); # with rand!
	> elapsed time: 0.899239837 seconds (212 MB allocated, 4.95% gc time in 9 pauses with 0 full sweep)

	= Better but still allocating, why?

	> @time foo=KUparser.gparse(dev[1:100], n, Feats.fv021a); # with predict
	> elapsed time: 9.124658661 seconds (254 MB allocated, 0.79% gc time in 11 pauses with 0 full sweep)

	* features.jl: get rid of avec allocation.
	* net.jl: find what allocates 6kb?

2015-03-03  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	= get rid of allocation
	= optimize feature extraction
	x cuda parser?
	x solve pmap problem (shared arrays, pointers?)

	* timing: dev is the 1700 sentences:
	sent_pct: 0.5888
	head_pct: 0.0894
	word_pct: 0.0785
	move_pct: 0.0340

	We are doing about 11 sentences/second: (90ms/sent)

	julia> @time foo=KUparser.gparse(dev[1:10], net, Fmats.fv021a)
	elapsed time: 1.078577283 seconds (65 MB allocated, 0.85% gc time in 3 pauses with 0 full sweep)
	julia> @time foo=KUparser.gparse(dev[1:100], net, Fmats.fv021a);
	elapsed time: 9.161665507 seconds (557 MB allocated, 0.80% gc time in 25 pauses with 0 full sweep)
	julia> @time foo=KUparser.gparse(dev, net, Fmats.fv021a);
	elapsed time: 152.361663243 seconds (9084 MB allocated, 1.26% gc time in 415 pauses with 0 full sweep)

	The feature construction is actually pretty fast: (10ms/sent)

	After replacing "predict" with "rand":
	julia> @time foo=KUparser.gparse(dev[1:100], net, Fmats.fv021a);
	elapsed time: 1.007098236 seconds (510 MB allocated, 11.25% gc time in 23 pauses with 0 full sweep)

	However there is too much allocation and speed can be improved.

	More impact would be to batch sentences first.

2014-10-27  Deniz Yuret  <dyuret@ku.edu.tr>

	* run_static_dynamic_1023_archybrid_conllWSJToken_wikipedia2MUNK_100_fv021a_0_333140404105682_ilac.out:
	First two epochs identical to 1017 run.  For conll07 use the 2014-10-10 result.
	:(copied from vectorparser/ChangeLog)

		stat_pct		move_pct	      	head_pct	      	word_pct
	epoch	trn	dev	tst	trn	dev	tst   	trn	dev	tst   	trn	dev	tst
	1	0.0142	0.0329	0.0346	0.0203	0.0409	0.0423	0.0590	0.1081	0.1134	0.0509	0.0946	0.0983
	2	0.0138	0.0376	0.0389	0.0136	0.0373	0.0374	0.0400	0.0994	0.1023	0.0359	0.0881	0.0912
	3	0.0102	0.0364	0.0380	0.0081	0.0351	0.0355	0.0269	0.0934	0.0969	0.0246	0.0832	0.0860
	4	0.0088	0.0361	0.0378	0.0058	0.0348	0.0352	0.0209	0.0921	0.0955	0.0193	0.0819	0.0845
	5	0.0076	0.0360	0.0376	0.0043	0.0342	0.0349	0.0174	0.0910	0.0950	0.0162	0.0810	0.0839
	6	0.0071	0.0359	0.0375	0.0033	0.0341	0.0347	0.0150	0.0907	0.0940	0.0142	0.0807	0.0835
	7	0.0068	0.0359	0.0374	0.0025	0.0336	0.0346	0.0131	0.0894	0.0940	0.0123	0.0795	0.0835
	8	0.0067	0.0360	0.0374	0.0023	0.0336	0.0343	0.0125	0.0892	0.0934	0.0118	0.0792	0.0832
	9	0.0068	0.0359	0.0377	0.0023	0.0333	0.0342	0.0125	0.0888	0.0935	0.0119	0.0789	0.0833
	10	0.0068	0.0358	0.0376	0.0021	0.0333	0.0342	0.0121	0.0885	0.0933	0.0116	0.0786	0.0830
	11	0.0068	0.0360	0.0377	0.0021	0.0335	0.0341	0.0120	0.0891	0.0928	0.0116	0.0792	0.0827
	12	0.0068	0.0361	0.0378	0.0021	0.0335	0.0341	0.0119	0.0889	0.0925	0.0116	0.0790	0.0824
	13	0.0068	0.0359	0.0379	0.0020	0.0332	0.0339	0.0117	0.0884	0.0920	0.0114	0.0785	0.0821
	14	0.0069	0.0359	0.0380	0.0020	0.0333	0.0340	0.0116	0.0888	0.0921	0.0112	0.0788	0.0823
	15	0.0068	0.0360	0.0380	0.0019	0.0334	0.0340	0.0115	0.0888	0.0920	0.0111	0.0787	0.0820
	16	0.0068	0.0364	0.0380	0.0019	0.0338	0.0340	0.0116	0.0899	0.0919	0.0113	0.0798	0.0820
	17	0.0069	0.0364	0.0379	0.0019	0.0337	0.0340	0.0114	0.0898	0.0918	0.0110	0.0799	0.0819
	18	0.0069	0.0363	0.0380	0.0018	0.0336	0.0341	0.0115	0.0894	0.0922	0.0110	0.0795	0.0823
	19	0.0069	0.0365	0.0380	0.0018	0.0336	0.0341	0.0115	0.0893	0.0921	0.0109	0.0795	0.0822
	20	0.0069	0.0364	0.0380	0.0017	0.0337	0.0342	0.0113	0.0894	0.0927	0.0108	0.0796	0.0827

2014-10-18  Deniz Yuret  <dyuret@ku.edu.tr>

	* features: only 11 common, marked by '+' below.

	>> c7 = load('archybrid_conll07EnglishToken_wikipedia2MUNK-100_rbf376678_1014_cache.mat');
	>> c8 = load ('archybrid_conllWSJToken_wikipedia2MUNK-100_rbf333140_cache.mat');
	>> [c71, c72, c73] = run_sort_bestfeats(c7.cache);
	>> [c81, c82, c83] = run_sort_bestfeats(c8.cache);


	fv022b/conll07				fv021a/conllWSJ

	+[-208]    '-n0w'       '[0 0 4]'   	+[-157]    '-s0w'       '[-1 0 4]'  
	+[-152]    '-s0w'       '[-1 0 4]'  	+[-141]    '-n0w'       '[0 0 4]'   
	+[ -69]    '-s1w'       '[-2 0 4]'  	+[ -70]    '-s1w'       '[-2 0 4]'  
	+[ -68]    '-n1w'       '[1 0 4]'   	+[ -55]    '-n1w'       '[1 0 4]'   
	+[ -60]    '-n0l1w'     '[0 -1 4]'  	-[ -21]    '-s2w'       '[-3 0 4]'  
	+[ -50]    '-n1c'       '[1 0 -4]'  	+[ -21]    '-s0l1w'     '[-1 -1 4]' 
	+[ -40]    '-s0c'       '[-1 0 -4]' 	+[ -21]    '-s0c'       '[-1 0 -4]' 
	+[ -34]    '-s0r1w'     '[-1 1 4]'  	+[ -18]    '-n0l1w'     '[0 -1 4]'  
	+[ -33]    '-n0c'       '[0 0 -4]'  	+[ -18]    '-n1c'       '[1 0 -4]'  
	-[ -32]    '-s0r<'      '[-1 0 6]'  	-[ -16]    '-s1r<'      '[-2 0 6]'  
	-[ -31]    '-s1d>'      '[-2 0 7]'  	-[ -16]    '-s0r='      '[-1 0 2]'  
	+[ -31]    '-s0l1w'     '[-1 -1 4]' 	+[ -15]    '-n0c'       '[0 0 -4]'  
	-[ -28]    '-s1l1c'     '[-2 -1 -4]'	-[ -14]    '-n0l1-'     '[0 -1 -1]' 
	-[ -28]    '-s0l1-'     '[-1 -1 -1]'	-[ -13]    '-s2r1l='    '[-3 1 -2]' 
	+[ -28]    '-n0l1c'     '[0 -1 -4]' 	+[ -13]    '-s0r1w'     '[-1 1 4]'  
	-[ -28]    '-s2aw'      '[-3 0 8]'  	-[ -11]    '-s1r1l='    '[-2 1 -2]' 
	-[ -25]    '-n0l='      '[0 0 -2]'  	-[ -11]    '-s0l1r='    '[-1 -1 2]' 
	-[ -22]    '-s1r1+'     '[-2 1 1]'  	-[  -9]    '-s0l1c'     '[-1 -1 -4]'
	-[ -20]    '-s1c'       '[-2 0 -4]' 	-[  -9]    '-s0-'       '[-1 0 -1]' 
	-[ -19]    '-s0h-'      '[-1 0 -9]' 	-[  -7]    '-s0r1r='    '[-1 1 2]'  
	-[ -11]    '-s1h-'      '[-2 0 -9]' 	+[  -7]    '-n0l1c'     '[0 -1 -4]' 
	-[  -4]    '-s1l1r>'    '[-2 -1 5]' 

2014-10-16  Deniz Yuret  <dyuret@ku.edu.tr>

	* Best-points: (copied from vectorparser/ChangeLog)

	corpus: conllWSJToken (trn02-21:39832s,950028w,1820392m;dev22:1700s,40117w,76834m;tst23:2416s,56684w,108536m)
	arctype: archybrid (TODO: can archybrid13 be the same?)
	embedding: wikipedia2MUNK-100
	feats: fv021a
	kernel: rbf
	gamma: 0.333140404105682
	devscore: 0.0325506937033084 (nsv=96326, single=0.0328500403467215)
	test: (TODO)

	corpus: conll07EnglishToken (trn:16588s,398439w,763702m;dev:1989s,48134w,92290m;trn+dev:18577s,446573w,855992m;tst:214s,5003w)
	arctype: archybrid
	embedding: wikipedia2MUNK-100 (TODO: other embeddings, bansal)
	feats: fv022b (TODO: compare with wsj feats)
	kernel: rbf
	gamma: 0.376747095368119
	tstscore: 0.0418668 (1-epoch full-trn/tst, nsv=57661)
	test: (TODO: debug run_static_dynamic)

2014-10-10  Deniz Yuret  <dyuret@ku.edu.tr>

	* conll07-dev: trn/dev/tst results (copied from vectorparser/ChangeLog)
	run_static_dynamic_1005_archybrid_conll07EnglishToken_wikipedia2MUNK_100_fv019_0_372063662109375_.out
	run/log2table.pl: extract table from log file:
	run/log2table.pl head_pct run_static_dynamic_1005_archybrid_conll07EnglishToken_wikipedia2MUNK_100_fv019_0_372063662109375_.out

	epoch	trn	dev	tst
	1	0.0644	0.1442	0.1455
	2	0.0408	0.1318	0.1403
	3	0.0211	0.1258	0.1317
	4	0.0148	0.1240	0.1305
	5	0.0108	0.1233	0.1269
	6	0.0087	0.1231	0.1267
	7	0.0073	0.1224	0.1235
	8	0.0065	0.1223	0.1235
	9	0.0063	0.1225	0.1235
	10	0.0060	0.1214	0.1219
	11	0.0060	0.1216	0.1219
	12	0.0056	0.1211	0.1201
	13	0.0056	0.1212	0.1219
	14	0.0055	0.1214	0.1221
	15	0.0053	0.1210	0.1217
	16	0.0052	0.1206	0.1229
	17	0.0050	0.1202	0.1241
	18	0.0050	0.1202	0.1243
	19	0.0048	0.1200	0.1239
	20	0.0049	0.1199	0.1251
