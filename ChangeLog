2015-03-18  Deniz Yuret  <dyuret@ku.edu.tr>

	* todo:
	- write cparser
	- try onur's problem
	- try bparser without dropout
	- alternative to adagrad?
	- try gparser with other fvectors
	- add options to gtrain.

2015-03-16  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	+ solve memory problems: x=10GB, bparse=100GB!
	+ save networks: implement savenet, testnet or copy:save copy:test
	- sizeof, print for nets?
	- beam earlystop? only train with mincostpath?  same with greedy?
	- play with optimization, rmsprop, adam, layers, dropout, hidden layers?
	- play with features
	- calculate word accuracy
	- debug gc()

	* memory:
	x do we need to wait for @everywhere gc()?
	x whos() does not work from inside meminfo: turn into macro?: still does not show locals
	= check out getBytes from http://stackoverflow.com/questions/28402989/check-size-in-bytes-of-variable-using-julia
	x if restarting workers does not help, just write code without DArrays.
	-- but DArrays are only used for corpora, not the returned x!?
	- maybe forget about workers and write multithreaded.

2015-03-15  Deniz Yuret  <dyuret@ku.edu.tr>

	* upper-bound: These are head accuracies with oracle parser (less than 100% because of nonplanar trees?)
	evalheads(p1,trn) => 0.9940970160879469
	evalheads(p2,dev) => 0.9950395094349029
	evalheads(p3,tst) => 0.9935960764942489

	* test/julia3_otrain_jl.out: Train using static oracle. 4m07s per epoch. (5m50s with testing)
	epoch	trn			dev			tst
	1	0.8739110847259238	0.8660916818306453	0.8615129489803119
	2	0.8855433734584665	0.8766607672557769	0.8707218968315574
	4	0.8988882432938818	0.8874541964753098	0.8828064356784984
	8	0.9100005473522885	0.8930877184236109	0.8891574341965987
	16	0.9229485867784949	0.9015130742577959	0.8943264413238303
	32	0.9391302151094494	0.9064486377346263	0.9001481899654223
	64	0.9567865368178622	0.9097639404741132	0.903288405899372
	128	0.9730323737826675	0.9098636488271805	0.9051054971420507
	256	0.9837520578340849	0.9088665652965077	0.9075047632488886

	* test/julia3_gtrain_jl.out: Train using greedy parser. 6m30s per epoch.
	1	0.8740110817786423	0.8695565470997333	0.8623244654576248
	2	0.8796424947475232	0.8704539222773388	0.8683755557123704
	4	0.8938568126413117	0.8808235909963357	0.8785018700162304
	8	0.9140688484970969	0.8979734277239075	0.8951732411262437
	16	0.9277031834851184	0.9051773562330184	0.9003246065909252
	32	0.941745927488453	0.9094149612383777	0.9050349304918496
	64	0.9574433595641392	0.9112595657701223	0.9091101545409639
	93	0.9657357467358857	0.9154223895106812	0.9110330957589443
	127	0.9721671361265142	0.9149986290101453	0.9128678286641733

	* test/julia3_btrain_jl.out: Train using beam parser. ~1h per epoch.
	1	0.8701039810002603	0.8869058005334397	0.882153694164138
	2	0.8951521543134597	0.8947079791609542	0.8900571589866629
	3	0.9055132348980205	0.8985467507540444	0.8948556912003387
	4	0.9123341030793707	0.9016875638756637	0.8973078822948275

2015-03-14  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/oparser.jl: Oracle parser: useful for generating static oracle training data.
	julia> @time o2=KUparser.oparse(dev,feats,20);
	elapsed time: 2.306022569 seconds (430 MB allocated, 44.86% gc time in 6 pauses with 3 full sweep)
	julia> mean(vcat(o1[1]...) .== vcat(map(x->x.head,dev)...))
	0.9950395094349029

	* src/gparser.jl:
	x do not need to allocate p, y, etc. for the whole corpus in batch version.

	* TODO:
	+ return xy from gparser and bparser.
	- train. (need logploss, need earlystop?, try rmsprop?, adam?: adagrad may not do well on changing data)
	= static oracle
	= greedy parser
	- beam parser: still has memory issues
	- feature select.

	* INFO:
	+ biyofiz gpu memory is sufficient for nbeam*nbatch*ncpu <= 10000

	julia> @time b42y=KUparser.bparse(dev,net,feats,100,5,20);
	elapsed time: 261.986853539 seconds (3 MB allocated)
	julia> @time b41y=KUparser.bparse(dev,net,feats,10,50,20);
	elapsed time: 32.315438529 seconds (3 MB allocated)
	julia> find(b41y .!= b42y)
	1-element Array{Int64,1}:
	1324

	+ beam parser gives better head score with same model:

	julia> gold=map(x->x.head, dev);
	julia> mean(vcat(gold...) .== vcat(g0...))
	0.9105865343869183
	julia> mean(vcat(gold...) .== vcat(b41y...))
	0.9154473165989481

	* TODO: src/bparser.jl: minibatch version:
        x do not keep computing costs for finished sentences: too minor
        x do all beam elements finish simultaneously?
        x cache cost in parser?
	x repeated states on the beam?
	= nbeam=10 and nbeam=100 give the same parse?
	== in all except sent 1324. beam1 vs beam10 differ in 224 sentences.

	* test/timing.jl: minibatch version speed test:

	# Greedy parser
	g0=KUparser.gparse(dev,gnet,feats)		elapsed time: 148.237107122 seconds
	g1=KUparser.gparse(dev,gnet,feats,1700)		elapsed time: 22.188889154 seconds
	g2=KUparser.gparse(dev,gnet,feats,1700,20)	elapsed time: 8.051600384 seconds
	g3=KUparser.gparse(dev,gnet,feats,100)		elapsed time: 26.318353452 seconds
	g4=KUparser.gparse(dev,gnet,feats,100,20)	elapsed time: 8.062792516 seconds

	# These are with beam size 1
	# Final parses same as g0
	b0=KUparser.bparse(dev,gnet,feats,1)		elapsed time: 156.000890758 seconds
	b1=KUparser.bparse(dev,gnet,feats,1,1700)	elapsed time: 30.145607698 seconds
	b2=KUparser.bparse(dev,gnet,feats,1,1700,20)	elapsed time: 8.18903106 seconds
	b3=KUparser.bparse(dev,gnet,feats,1,100)	elapsed time: 31.510566003 seconds
	b4=KUparser.bparse(dev,gnet,feats,1,100,20)	elapsed time: 8.234869093 seconds

	# These are with beam size 10 on the first 100 sentences of dev:
	# Final parses not same with g0[1:100]
	b01=KUparser.bparse(dev[1:100],gnet,feats,10)		elapsed time: 25.057099378 seconds
	b11=KUparser.bparse(dev[1:100],gnet,feats,10,100)	elapsed time: 14.705737159 seconds
	b21=KUparser.bparse(dev[1:100],gnet,feats,10,100,20)	elapsed time: 5.154158539 seconds
	b31=KUparser.bparse(dev[1:100],gnet,feats,10,10)	elapsed time: 16.469459534 seconds
	b41=KUparser.bparse(dev[1:100],gnet,feats,10,10,20)	elapsed time: 5.161457464 seconds

	# These are with beam size 100 on the first 100 sentences of dev:
	# Final parses same as b01
	b02=KUparser.bparse(dev[1:100],gnet,feats,100)		elapsed time: 137.201635533 seconds
	b12=KUparser.bparse(dev[1:100],gnet,feats,100,100)	elapsed time: 132.684041541 seconds
	b22=KUparser.bparse(dev[1:100],gnet,feats,100,100,20)	elapsed time: 18.501004294 seconds
	b32=KUparser.bparse(dev[1:100],gnet,feats,100,10)	elapsed time: 132.337806865 seconds
	b42=KUparser.bparse(dev[1:100],gnet,feats,100,10,20)	elapsed time: 18.514346591 seconds


2015-03-13  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/bparser.jl: speed test:

	# Time for greedy parser on 1700 sentence dev
	julia> @time g=KUparser.gparse(dev,gnet,feats);
	elapsed time: 149.497789522 seconds (4116 MB allocated, 1.06% gc time in 189 pauses with 0 full sweep)

	# Time for beam parser on same data with beam=1
	julia> @time b=KUparser.bparse(dev,gnet,feats,1);
	elapsed time: 159.778490775 seconds (7173 MB allocated, 3.76% gc time in 328 pauses with 9 full sweep)

	# Time on dev[1:100]
	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,1);
	elapsed time: 9.962360704 seconds (440 MB allocated, 5.42% gc time in 20 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,5);
	elapsed time: 16.47657518 seconds (1940 MB allocated, 8.55% gc time in 89 pauses with 2 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,10);
	elapsed time: 27.863031912 seconds (3773 MB allocated, 12.66% gc time in 172 pauses with 6 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,50);
	elapsed time: 84.229235102 seconds (17997 MB allocated, 18.13% gc time in 806 pauses with 25 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,100);
	elapsed time: 158.230640377 seconds (35313 MB allocated, 16.89% gc time in 1549 pauses with 41 full sweep)

	# Time tests with ncpu=20

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,1,20);
	elapsed time: 9.237851461 seconds (2 MB allocated)
	elapsed time: 9.766501577 seconds (107 MB allocated, 4.21% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,5,20);
	elapsed time: 9.447347633 seconds (2 MB allocated)
	elapsed time: 9.975221305 seconds (107 MB allocated, 4.11% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,10,20);
	elapsed time: 13.658449233 seconds (2 MB allocated)
	elapsed time: 14.184126282 seconds (107 MB allocated, 2.89% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,50,20);
	elapsed time: 15.286421047 seconds (2 MB allocated)
	elapsed time: 15.809166647 seconds (107 MB allocated, 2.60% gc time in 3 pauses with 1 full sweep)

	julia> @time b=KUparser.bparse(dev[1:100],gnet,feats,100,20);
	elapsed time: 27.447839359 seconds (2 MB allocated)
	elapsed time: 28.380576273 seconds (107 MB allocated, 2.96% gc time in 5 pauses with 2 full sweep)


2015-03-12  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO: src/bparser.jl:
	- early stop?  could implement by copying into big x
	-- mincost may not be 0 for non-planar sentences
	= sortperm! suggest AbstractArray to julia
	= Now we sort the nc candidates and copy top np back to the beam
	x softperm! may not be necessary when nc <= beam (unless we care about the first candidate being the best)
	= do we need features when we have 0 or 1 valid move?
	= do not return y from gparser, return x,z consistently from each method
	x maybe have optional trn struct and return trn.x trn.y trn.nx
	x check for identical states on the beam: score will be difft

2015-03-08  Deniz Yuret  <dyuret@ku.edu.tr>

	* Speed-test:

	julia@iui> @time KUparser.gparse(trn, net, feats, 2000, 20);
	elapsed time: 40.50693341 seconds (9502 MB allocated, 8.38% gc time in 14 pauses with 11 full sweep)
	elapsed time: 86.205662824 seconds (107430 MB allocated, 6.12% gc time in 86 pauses with 14 full sweep)

	julia@bio> @time KUparser.gparse(trn, net, feats, 500, 20);
	elapsed time: 75.61331844 seconds (9476 MB allocated, 3.19% gc time in 8 pauses with 6 full sweep)
	elapsed time: 112.552530706 seconds (107352 MB allocated, 4.21% gc time in 75 pauses with 9 full sweep)

	julia3@ilac> @time KUparser.gparse(trn, net, feats, 1700, 12);
	elapsed time: 86.231203 seconds (11419169336 bytes allocated, 7.88% gc time)
	elapsed time: 123.933778 seconds (75581738656 bytes allocated, 16.60% gc time)

2015-03-05  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	= write bparser
	- can we use rnn's to learn parser-action sequences?
	- real use of rnn's is to map text to meaning!

	= should we try parallel for?
	= see how SharedArray is implemented and use it for net weights: x is bigger!

	* src/gparser.jl: gpu minibatch version:

	# dev has 1700 sentences and 40117 words
	# fastest matlab test speed was 26 sents/sec = 1.6298 ms/word
	# fastest matlab dump speed was 30 sents/sec = 1.4125 ms/word
	# fastest julia test speed is 80 sents/sec = 0.5286 ms/word
	# fastest julia dump speed is 116 sents/sec = 0.3652 ms/word

	# 3.6986 ms/word: parsing sentences one at a time
	include("fooparser.jl")
	julia> @time h2=KUparser.gparse(dev, n, Feats.fv021a);
	elapsed time: 148.37933571 seconds (4145 MB allocated, 0.83% gc time in 190 pauses with 0 full sweep)

	# 0.5286 ms/word: parsing sentences in minibatches
	julia> @time h1=KUparser.gparse(dev, n, Feats.fv021a, 1700);
	elapsed time: 21.206189373 seconds (6355 MB allocated, 8.16% gc time in 273 pauses with 1 full sweep)

	# 0.3652 ms/word: everything except KUnet prediction
	julia> @time h0=KUparser.gparse(dev, n, Feats.fv021a, false);
	elapsed time: 14.648858577 seconds (3488 MB allocated, 5.64% gc time in 160 pauses with 0 full sweep)

	# For training with Julia I expect 8 mins to parse, 2 mins to
	update, 10 mins per epoch.

2015-03-04  Deniz Yuret  <dyuret@ku.edu.tr>

	* src/features.jl:
	> @time foo=KUparser.gparse(dev[1:100], n, Feats.fv021a); # with rand!
	> elapsed time: 0.899239837 seconds (212 MB allocated, 4.95% gc time in 9 pauses with 0 full sweep)

	= Better but still allocating, why?

	> @time foo=KUparser.gparse(dev[1:100], n, Feats.fv021a); # with predict
	> elapsed time: 9.124658661 seconds (254 MB allocated, 0.79% gc time in 11 pauses with 0 full sweep)

	* features.jl: get rid of avec allocation.
	* net.jl: find what allocates 6kb?

2015-03-03  Deniz Yuret  <dyuret@ku.edu.tr>

	* TODO:
	= get rid of allocation
	= optimize feature extraction
	x cuda parser?
	x solve pmap problem (shared arrays, pointers?)

	* timing: dev is the 1700 sentences:
	sent_pct: 0.5888
	head_pct: 0.0894
	word_pct: 0.0785
	move_pct: 0.0340

	We are doing about 11 sentences/second: (90ms/sent)

	julia> @time foo=KUparser.gparse(dev[1:10], net, Fmats.fv021a)
	elapsed time: 1.078577283 seconds (65 MB allocated, 0.85% gc time in 3 pauses with 0 full sweep)
	julia> @time foo=KUparser.gparse(dev[1:100], net, Fmats.fv021a);
	elapsed time: 9.161665507 seconds (557 MB allocated, 0.80% gc time in 25 pauses with 0 full sweep)
	julia> @time foo=KUparser.gparse(dev, net, Fmats.fv021a);
	elapsed time: 152.361663243 seconds (9084 MB allocated, 1.26% gc time in 415 pauses with 0 full sweep)

	The feature construction is actually pretty fast: (10ms/sent)

	After replacing "predict" with "rand":
	julia> @time foo=KUparser.gparse(dev[1:100], net, Fmats.fv021a);
	elapsed time: 1.007098236 seconds (510 MB allocated, 11.25% gc time in 23 pauses with 0 full sweep)

	However there is too much allocation and speed can be improved.

	More impact would be to batch sentences first.
